"""
Chat API - Step 6: LangChain + Natural Language Processing
ìì—°ì–´ â†’ QueryPlan â†’ Core API â†’ RenderSpec

Text-to-SQL ëª¨ë“œ ì¶”ê°€:
SQL_ENABLE_TEXT_TO_SQL=true ì„¤ì • ì‹œ AIê°€ ì§ì ‘ SQLì„ ìƒì„±í•˜ì—¬ ì½ê¸° ì „ìš© DBì—ì„œ ì‹¤í–‰
"""

from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any, List, Generator
import httpx
import logging
import os
import re
import uuid
import csv
import io
from datetime import datetime

# Text-to-SQL ëª¨ë“œ í”Œë˜ê·¸
ENABLE_TEXT_TO_SQL = os.getenv("SQL_ENABLE_TEXT_TO_SQL", "false").lower() == "true"


def to_camel(string: str) -> str:
    """snake_caseë¥¼ camelCaseë¡œ ë³€í™˜"""
    components = string.split('_')
    return components[0] + ''.join(x.title() for x in components[1:])


def summarize_query_plan(query_plan: Dict[str, Any]) -> str:
    """QueryPlanì„ ê°„ë‹¨í•œ ìš”ì•½ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    parts = []

    entity = query_plan.get("entity", "")
    if entity:
        parts.append(entity)

    # í•„í„° ìš”ì•½
    filters = query_plan.get("filters", [])
    if filters:
        filter_strs = [f"{f.get('field')} {f.get('operator')} {f.get('value')}" for f in filters]
        parts.append(f"filters:[{', '.join(filter_strs)}]")

    # limit
    if query_plan.get("limit"):
        parts.append(f"limit:{query_plan['limit']}")

    # orderBy
    order_by = query_plan.get("orderBy", [])
    if order_by:
        order_strs = [f"{o.get('field')} {o.get('direction', 'asc')}" for o in order_by]
        parts.append(f"orderBy:[{', '.join(order_strs)}]")

    return ", ".join(parts) if parts else "[ì¿¼ë¦¬ ì—†ìŒ]"


def build_conversation_context(history: List["ChatMessageItem"]) -> str:
    """ì´ì „ ëŒ€í™”ë¥¼ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ë‹¤ì¤‘ ê²°ê³¼ ìƒí™© ëª…ì‹œ í¬í•¨)"""
    if not history:
        return ""

    context = "## ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸\n\n"

    # ============================================
    # [NEW] ë‹¤ì¤‘ ê²°ê³¼ ìƒí™© ëª…ì‹œ ì„¹ì…˜
    # ============================================
    result_messages = []
    for i, msg in enumerate(history):
        if msg.role == "assistant" and msg.queryResult:
            entity = msg.queryPlan.get("entity", "unknown") if msg.queryPlan else "unknown"
            count = msg.queryResult.get("totalCount", 0)
            # í•„í„° ì •ë³´ë„ ì¶”ê°€ (ê°™ì€ entityë¼ë„ ì¡°ê±´ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            filters = msg.queryPlan.get("filters", []) if msg.queryPlan else []
            filter_desc = ""
            if filters:
                filter_strs = [f"{f.get('field')}={f.get('value')}" for f in filters[:2]]
                filter_desc = f" ({', '.join(filter_strs)})"
            result_messages.append({
                "index": i,
                "entity": entity,
                "count": count,
                "filter_desc": filter_desc,
                "is_latest": False
            })

    if result_messages:
        result_messages[-1]["is_latest"] = True  # ë§ˆì§€ë§‰ì´ ì§ì „ ê²°ê³¼

        context += "### ğŸ“Š í˜„ì¬ ì„¸ì…˜ì˜ ì¡°íšŒ ê²°ê³¼ í˜„í™©\n"
        for r in result_messages:
            marker = "ğŸ‘‰ (ì§ì „)" if r["is_latest"] else ""
            context += f"- ê²°ê³¼ #{r['index']}: {r['entity']} {r['count']}ê±´{r['filter_desc']} {marker}\n"

        if len(result_messages) > 1:
            # ë‹¤ì¤‘ ê²°ê³¼ ê²½ê³  - LLMì´ ì£¼ëª©í•˜ë„ë¡
            entities = set(r["entity"] for r in result_messages)
            if len(entities) > 1:
                context += f"\nâš ï¸ **ë‹¤ë¥¸ ì¢…ë¥˜ì˜ ê²°ê³¼ê°€ {len(result_messages)}ê°œ ìˆìŠµë‹ˆë‹¤** ({', '.join(entities)})\n"
                context += "â†’ ì‚¬ìš©ìê°€ íŠ¹ì • ê²°ê³¼ë¥¼ ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ needs_result_clarification=true ê¶Œì¥\n"
            else:
                context += f"\nğŸ“Œ ë™ì¼ ì—”í‹°í‹°({list(entities)[0]}) ê²°ê³¼ê°€ {len(result_messages)}ê°œ ìˆìŠµë‹ˆë‹¤ (ì¡°ê±´ì´ ë‹¤ë¦„).\n"
                context += "â†’ ì°¸ì¡° í‘œí˜„ ì—†ì´ ì§‘ê³„/í•„í„° ìš”ì²­ ì‹œ needs_result_clarification=true ê³ ë ¤\n"
        context += "\n"

    # ============================================
    # ëŒ€í™” íˆìŠ¤í† ë¦¬ (ê¸°ì¡´ ìœ ì§€)
    # ============================================
    context += "### ëŒ€í™” íˆìŠ¤í† ë¦¬\n"
    for msg in history[-5:]:
        if msg.role == 'user':
            context += f"ì‚¬ìš©ì: {msg.content}\n"
        else:
            # queryPlan ìš”ì•½ í¬í•¨
            if msg.queryPlan:
                plan_summary = summarize_query_plan(msg.queryPlan)
                context += f"ì–´ì‹œìŠ¤í„´íŠ¸: [ì¿¼ë¦¬: {plan_summary}]\n"
            else:
                context += f"ì–´ì‹œìŠ¤í„´íŠ¸: [ê²°ê³¼ í‘œì‹œë¨]\n"

            # ì§‘ê³„ ê²°ê³¼ê°’ í¬í•¨ (ì¤‘ìš”: í›„ì† ê³„ì‚°ìš©)
            if msg.renderSpec and msg.renderSpec.get("type") == "text":
                text_content = msg.renderSpec.get("text", {}).get("content", "")
                if text_content and ("í•©ê³„" in text_content or "$" in text_content or "ì›" in text_content):
                    context += f"  â†’ ì§‘ê³„ ê²°ê³¼: {text_content}\n"

    # ============================================
    # í›„ì† ì§ˆë¬¸ ì²˜ë¦¬ ê·œì¹™ (ê°œì„ )
    # ============================================
    context += "\n### í›„ì† ì§ˆë¬¸ ì²˜ë¦¬ ê·œì¹™\n"
    context += "1. 'ì´ì¤‘ì—', 'ì—¬ê¸°ì„œ', 'ì§ì „', 'ë°©ê¸ˆ' ë“± ì°¸ì¡° í‘œí˜„ â†’ **ì§ì „ ê²°ê³¼ ì‚¬ìš©**, needs_result_clarification=false\n"
    context += "2. ì°¸ì¡° í‘œí˜„ ì—†ì´ ì§‘ê³„/í•„í„° ìš”ì²­ + ë‹¤ì¤‘ ê²°ê³¼ â†’ needs_result_clarification=true ê³ ë ¤\n"
    context += "3. í›„ì† ì§ˆë¬¸ì—ì„œëŠ” **ì´ì „ ì—”í‹°í‹° ìœ ì§€** (ë‹¤ë¥¸ ì—”í‹°í‹°ë¡œ ë³€ê²½ ê¸ˆì§€)\n"
    context += "4. ì´ì „ ì§‘ê³„ ê²°ê³¼ì— ëŒ€í•œ ì‚°ìˆ  ì—°ì‚° â†’ query_intent=direct_answer\n"
    return context


def get_previous_query_plan(history: List["ChatMessageItem"]) -> Optional[Dict[str, Any]]:
    """ì´ì „ ëŒ€í™”ì—ì„œ ë§ˆì§€ë§‰ queryPlan ì¶”ì¶œ"""
    if not history:
        return None

    # ì—­ìˆœìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ ê°€ì¥ ìµœê·¼ assistantì˜ queryPlan ì°¾ê¸°
    for msg in reversed(history):
        if msg.role == 'assistant' and msg.queryPlan:
            return msg.queryPlan
    return None


def extract_previous_results(history: List["ChatMessageItem"]) -> List[Dict[str, Any]]:
    """ì´ì „ ëŒ€í™”ì—ì„œ ì¡°íšŒ/ì§‘ê³„ ê²°ê³¼ ìš”ì•½ ì¶”ì¶œ (Intent Classificationìš©)

    ì‹¤ì œ ë°ì´í„° ê°’ë„ ì¶”ì¶œí•˜ì—¬ LLMì´ ê³„ì‚°í•  ìˆ˜ ìˆë„ë¡ í•¨
    """
    results = []
    if not history:
        return results

    for i, msg in enumerate(history):
        if msg.role == "assistant":
            result_info = {
                "index": i,
                "entity": None,
                "count": 0,
                "aggregation": None,
                "data_summary": None,  # ì‹¤ì œ ë°ì´í„° ìš”ì•½
                "total_amount": None   # ê¸ˆì•¡ í•©ê³„ (ìˆëŠ” ê²½ìš°)
            }

            # QueryResultê°€ ìˆìœ¼ë©´ ì¡°íšŒ ê²°ê³¼
            if msg.queryResult:
                logger.info(f"[extract_previous_results] msg #{i} has queryResult with keys: {list(msg.queryResult.keys())}")
                result_info["count"] = msg.queryResult.get("totalCount", 0)
                if msg.queryPlan:
                    result_info["entity"] = msg.queryPlan.get("entity", "unknown")

                # ì‹¤ì œ ë°ì´í„°ì—ì„œ ê¸ˆì•¡ í•©ê³„ ì¶”ì¶œ
                data_obj = msg.queryResult.get("data", {})
                # data is an object with 'rows' property according to query-result.schema.json
                rows = data_obj.get("rows", []) if isinstance(data_obj, dict) else []
                logger.info(f"[extract_previous_results] msg #{i} rows length: {len(rows) if rows else 0}")

                if rows:
                    # amount í•„ë“œê°€ ìˆìœ¼ë©´ í•©ê³„ ê³„ì‚°
                    amounts = []
                    for row_idx, row in enumerate(rows):
                        if isinstance(row, dict):
                            logger.info(f"[extract_previous_results] msg #{i} row #{row_idx} keys: {list(row.keys())}")
                            # amount, totalAmount, ê¸ˆì•¡ ë“± ë‹¤ì–‘í•œ í•„ë“œëª… ì²´í¬
                            for field in ["amount", "totalAmount", "total_amount", "price", "ê¸ˆì•¡"]:
                                if field in row and row[field] is not None:
                                    try:
                                        amounts.append(float(row[field]))
                                        logger.info(f"[extract_previous_results] msg #{i} row #{row_idx} found {field}={row[field]}")
                                    except (ValueError, TypeError) as e:
                                        logger.info(f"[extract_previous_results] msg #{i} row #{row_idx} error converting {field}: {e}")
                                        pass
                                    break
                        else:
                            logger.info(f"[extract_previous_results] msg #{i} row #{row_idx} is not a dict: {type(row)}")

                    if amounts:
                        result_info["total_amount"] = sum(amounts)
                        result_info["data_summary"] = f"ê¸ˆì•¡ í•©ê³„: ${result_info['total_amount']:,.0f} ({len(amounts)}ê±´)"
                        logger.info(f"[extract_previous_results] msg #{i} extracted total_amount: ${result_info['total_amount']:,.0f} from {len(amounts)} amounts")
                    else:
                        logger.info(f"[extract_previous_results] msg #{i} no amounts found in {len(rows)} rows")

            # RenderSpecì´ text íƒ€ì…ì´ë©´ ì§‘ê³„ ê²°ê³¼ì¼ ìˆ˜ ìˆìŒ
            if msg.renderSpec and msg.renderSpec.get("type") == "text":
                text_content = msg.renderSpec.get("text", {}).get("content", "")
                if text_content:
                    result_info["aggregation"] = text_content

                    # í…ìŠ¤íŠ¸ì—ì„œ ê¸ˆì•¡ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„: ê´„í˜¸ ì•ˆ ì „ì²´ ê¸ˆì•¡ > ì¶•ì•½ ê¸ˆì•¡)
                    if result_info["total_amount"] is None:
                        # 1ìˆœìœ„: ê´„í˜¸ ì•ˆì˜ ì „ì²´ ê¸ˆì•¡ (ì˜ˆ: "$2.88M ($2,878,000)" â†’ 2878000)
                        full_amount_match = re.search(r'\(\$?([\d,]+)\)', text_content)
                        if full_amount_match:
                            try:
                                result_info["total_amount"] = float(full_amount_match.group(1).replace(',', ''))
                                logger.info(f"[extract_previous_results] Extracted full amount from parens: ${result_info['total_amount']:,.0f}")
                            except ValueError:
                                pass

                        # 2ìˆœìœ„: M/K ì ‘ë¯¸ì‚¬ ì²˜ë¦¬ (ì˜ˆ: "$2.88M" â†’ 2880000)
                        if result_info["total_amount"] is None:
                            abbrev_match = re.search(r'\$?([\d,]+(?:\.\d+)?)\s*([MK])', text_content)
                            if abbrev_match:
                                try:
                                    value = float(abbrev_match.group(1).replace(',', ''))
                                    suffix = abbrev_match.group(2)
                                    if suffix == 'M':
                                        value *= 1_000_000
                                    elif suffix == 'K':
                                        value *= 1_000
                                    result_info["total_amount"] = value
                                    logger.info(f"[extract_previous_results] Extracted abbreviated amount: ${result_info['total_amount']:,.0f}")
                                except ValueError:
                                    pass

                        # 3ìˆœìœ„: ì¼ë°˜ ê¸ˆì•¡ (ì˜ˆ: "$1,234,567")
                        if result_info["total_amount"] is None:
                            simple_match = re.search(r'\$?([\d,]+(?:\.\d+)?)', text_content)
                            if simple_match:
                                try:
                                    result_info["total_amount"] = float(simple_match.group(1).replace(',', ''))
                                    logger.info(f"[extract_previous_results] Extracted simple amount: ${result_info['total_amount']:,.0f}")
                                except ValueError:
                                    pass

            # ì¡°íšŒ ê²°ê³¼ë‚˜ ì§‘ê³„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if result_info["count"] > 0 or result_info["aggregation"]:
                results.append(result_info)
                logger.info(f"[extract_previous_results] Added result #{len(results)}: entity={result_info['entity']}, count={result_info['count']}, total_amount={result_info['total_amount']}")

    logger.info(f"[extract_previous_results] Total results extracted: {len(results)}")
    return results


def merge_filters(previous_plan: Dict[str, Any], new_plan: Dict[str, Any]) -> Dict[str, Any]:
    """ì´ì „ í•„í„°ì™€ ìƒˆ í•„í„°ë¥¼ ë³‘í•©"""
    if not previous_plan:
        return new_plan

    # clarification ìš”ì²­ì´ë©´ ë³‘í•©í•˜ì§€ ì•ŠìŒ
    if new_plan.get("needs_clarification"):
        return new_plan

    # ì´ì „ í•„í„° ê°€ì ¸ì˜¤ê¸°
    prev_filters = previous_plan.get("filters", [])
    new_filters = new_plan.get("filters", [])

    # ìƒˆ í•„í„°ì˜ í•„ë“œëª… ëª©ë¡
    new_filter_fields = {f.get("field") for f in new_filters}

    # ì´ì „ í•„í„° ì¤‘ ìƒˆ í•„í„°ì— ì—†ëŠ” ê²ƒë§Œ ë³‘í•© (ì¤‘ë³µ í•„ë“œ ë°©ì§€)
    merged_filters = list(new_filters)  # ìƒˆ í•„í„° ìš°ì„ 
    for prev_filter in prev_filters:
        if prev_filter.get("field") not in new_filter_fields:
            merged_filters.append(prev_filter)

    # ë³‘í•©ëœ ê²°ê³¼
    merged_plan = dict(new_plan)
    if merged_filters:
        merged_plan["filters"] = merged_filters

    # ì´ì „ entity ìœ ì§€ (ìƒˆ planì— entityê°€ ì—†ìœ¼ë©´)
    if not merged_plan.get("entity") and previous_plan.get("entity"):
        merged_plan["entity"] = previous_plan["entity"]

    # ì´ì „ limit ìœ ì§€ (ìƒˆ planì´ ê¸°ë³¸ê°’ 10ì´ë©´)
    if merged_plan.get("limit") == 10 and previous_plan.get("limit"):
        merged_plan["limit"] = previous_plan["limit"]

    return merged_plan

from app.services.query_planner import get_query_planner, IntentType
from app.services.render_composer import get_render_composer
from app.services.rag_service import get_rag_service

# Text-to-SQL ëª¨ë“œìš© import (ì¡°ê±´ë¶€)
if ENABLE_TEXT_TO_SQL:
    from app.services.text_to_sql import get_text_to_sql_service

logger = logging.getLogger(__name__)
logger.info(f"Text-to-SQL mode: {'ENABLED' if ENABLE_TEXT_TO_SQL else 'DISABLED'}")

router = APIRouter()

# Configuration
CORE_API_URL = os.getenv("CORE_API_URL", "http://localhost:8080")
ENABLE_QUERY_PLAN_VALIDATION = os.getenv("ENABLE_QUERY_PLAN_VALIDATION", "true").lower() == "true"


class ChatMessageItem(BaseModel):
    """ëŒ€í™” ë©”ì‹œì§€ ì•„ì´í…œ"""
    id: str
    role: str  # 'user' | 'assistant'
    content: str
    timestamp: str
    status: Optional[str] = None
    renderSpec: Optional[Dict[str, Any]] = None
    queryResult: Optional[Dict[str, Any]] = None
    queryPlan: Optional[Dict[str, Any]] = None  # ì´ì „ ì¿¼ë¦¬ ì¡°ê±´ ì €ì¥ìš©


class ChatRequest(BaseModel):
    """ì±„íŒ… ìš”ì²­"""
    message: str
    conversation_id: Optional[str] = None
    session_id: Optional[str] = Field(default=None, alias="sessionId")
    conversation_history: Optional[List[ChatMessageItem]] = Field(default=None, alias="conversationHistory")

    class Config:
        populate_by_name = True


class ChatResponse(BaseModel):
    """ì±„íŒ… ì‘ë‹µ - UI íƒ€ì…ê³¼ ì¼ì¹˜"""
    request_id: str = Field(alias="requestId")
    render_spec: Dict[str, Any] = Field(alias="renderSpec")
    query_result: Optional[Dict[str, Any]] = Field(default=None, alias="queryResult")  # filter_local ì‹œ None ê°€ëŠ¥
    query_plan: Dict[str, Any] = Field(alias="queryPlan")  # ì´ë²ˆ ì¿¼ë¦¬ ì¡°ê±´ (í›„ì† ì§ˆë¬¸ìš©)
    ai_message: Optional[str] = Field(default=None, alias="aiMessage")
    timestamp: str

    class Config:
        populate_by_name = True


@router.post("/chat", response_model=ChatResponse, response_model_by_alias=True)
async def chat(request: ChatRequest):
    """
    Step 6: LangChain ê¸°ë°˜ ìì—°ì–´ ì²˜ë¦¬

    Flow (ê¸°ì¡´ QueryPlan ëª¨ë“œ):
    1. ì‚¬ìš©ì ë©”ì‹œì§€ ìˆ˜ì‹ 
    2. QueryPlannerServiceë¡œ ìì—°ì–´ â†’ QueryPlan ë³€í™˜
    3. Core API í˜¸ì¶œ
    4. RenderComposerServiceë¡œ QueryResult â†’ RenderSpec ë³€í™˜
    5. RenderSpec ë°˜í™˜

    Flow (Text-to-SQL ëª¨ë“œ, SQL_ENABLE_TEXT_TO_SQL=true):
    1. ì‚¬ìš©ì ë©”ì‹œì§€ ìˆ˜ì‹ 
    2. TextToSqlServiceë¡œ ìì—°ì–´ â†’ SQL ë³€í™˜
    3. SQL ê²€ì¦ (SqlValidator)
    4. ì½ê¸° ì „ìš© DBì—ì„œ ì§ì ‘ ì‹¤í–‰
    5. ê²°ê³¼ë¥¼ RenderSpecìœ¼ë¡œ ë³€í™˜
    """
    start_time = datetime.utcnow()
    conversation_id = request.conversation_id or str(uuid.uuid4())
    request_id = f"req-{uuid.uuid4().hex[:8]}"

    logger.info(f"[{request_id}] Received message: {request.message}")

    processing_info = {
        "requestId": request_id,
        "stages": []
    }

    # ========================================
    # Text-to-SQL ëª¨ë“œ ë¶„ê¸°
    # ========================================
    if ENABLE_TEXT_TO_SQL:
        return await handle_text_to_sql(request, request_id, start_time)

    try:
        # Stage 0: Intent Classification (2ë‹¨ê³„ ë¶„ë¥˜)
        stage_start = datetime.utcnow()
        query_planner = get_query_planner()

        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¹Œë“œ
        conversation_context = None
        previous_results = []
        if request.conversation_history:
            conversation_context = build_conversation_context(request.conversation_history)
            previous_results = extract_previous_results(request.conversation_history)
            logger.info(f"[{request_id}] Using conversation context with {len(request.conversation_history)} messages")
            logger.info(f"[{request_id}] Found {len(previous_results)} previous results for intent classification")

        # 1ë‹¨ê³„: Intent ë¶„ë¥˜ (ê°€ë²¼ìš´ ëª¨ë¸ë¡œ ë¹ ë¥´ê²Œ)
        intent_result = await query_planner.classify_intent(
            request.message,
            conversation_context or "",
            previous_results
        )
        logger.info(f"[{request_id}] Intent classification: {intent_result.intent.value}, confidence={intent_result.confidence:.2f}")

        # direct_answerë©´ ë°”ë¡œ ì‘ë‹µ ë°˜í™˜ (QueryPlan ìƒì„± ìŠ¤í‚µ)
        if intent_result.intent == IntentType.DIRECT_ANSWER and intent_result.direct_answer_text:
            logger.info(f"[{request_id}] Direct answer detected, skipping QueryPlan generation")
            logger.info(f"[{request_id}] Direct answer text: {intent_result.direct_answer_text}")

            return ChatResponse(
                request_id=request_id,
                query_plan={
                    "query_intent": "direct_answer",
                    "requestId": request_id
                },
                query_result=None,
                render_spec={
                    "type": "text",
                    "text": {
                        "content": intent_result.direct_answer_text,
                        "format": "markdown"
                    },
                    "metadata": {
                        "intent": "direct_answer",
                        "confidence": intent_result.confidence,
                        "reasoning": intent_result.reasoning
                    }
                },
                timestamp=datetime.utcnow().isoformat() + "Z"
            )

        processing_info["stages"].append({
            "name": "Intent Classification",
            "duration": (datetime.utcnow() - stage_start).total_seconds() * 1000,
            "result": intent_result.intent.value
        })

        # Stage 1: Natural Language â†’ QueryPlan
        stage_start = datetime.utcnow()

        query_plan = await query_planner.generate_query_plan(
            request.message,
            conversation_context=conversation_context,
            enable_validation=ENABLE_QUERY_PLAN_VALIDATION
        )

        # LLMì´ íŒë‹¨í•œ ì˜ë„ì— ë”°ë¼ í•„í„° ë³‘í•© ê²°ì •
        query_intent = query_plan.get("query_intent", "new_query")
        logger.info(f"[{request_id}] Query intent: {query_intent}")

        if query_intent == "refine_previous":
            if request.conversation_history:
                previous_plan = get_previous_query_plan(request.conversation_history)
                if previous_plan:
                    logger.info(f"[{request_id}] Intent: refine_previous, merging with previous filters")
                    logger.info(f"[{request_id}] Previous plan: {previous_plan}")
                    query_plan = merge_filters(previous_plan, query_plan)
                    logger.info(f"[{request_id}] Merged plan: {query_plan}")
        elif query_intent == "filter_local":
            # í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ í•„í„°ë§: Core API í˜¸ì¶œ ì—†ì´ í•„í„° ì¡°ê±´ë§Œ ë°˜í™˜
            logger.info(f"[{request_id}] Intent: filter_local, client-side filtering")

            # entityê°€ ì—†ìœ¼ë©´ ì´ì „ queryPlanì—ì„œ ìƒì†
            if not query_plan.get("entity") and request.conversation_history:
                previous_plan = get_previous_query_plan(request.conversation_history)
                if previous_plan and previous_plan.get("entity"):
                    query_plan["entity"] = previous_plan["entity"]
                    logger.info(f"[{request_id}] Inherited entity from previous plan: {query_plan['entity']}")

            # ì´ì „ ê²°ê³¼ê°€ ìˆëŠ” ë©”ì‹œì§€ë“¤ ì°¾ê¸°
            result_messages = []
            if request.conversation_history:
                logger.info(f"[{request_id}] Checking {len(request.conversation_history)} messages in history")
                for i, msg in enumerate(request.conversation_history):
                    has_query_result = msg.queryResult is not None
                    logger.info(f"[{request_id}] Message {i}: role={msg.role}, hasQueryResult={has_query_result}")
                    if msg.role == "assistant" and msg.queryResult:
                        result_messages.append((i, msg))

            logger.info(f"[{request_id}] Found {len(result_messages)} result messages")

            # 1ë‹¨ê³„: LLMì´ ëª¨í˜¸í•˜ë‹¤ê³  íŒë‹¨í–ˆëŠ”ì§€ í™•ì¸
            needs_result_clarification = query_plan.get("needs_result_clarification", False)
            logger.info(f"[{request_id}] 1st stage LLM decision: needs_result_clarification={needs_result_clarification}")

            # 2ë‹¨ê³„: ë‹¤ì¤‘ ê²°ê³¼ + 1ë‹¨ê³„ê°€ Falseë©´ ìƒìœ„ ëª¨ë¸ë¡œ ì¬íŒë‹¨
            if len(result_messages) > 1 and not needs_result_clarification:
                logger.info(f"[{request_id}] Multiple results but 1st stage said no clarification, invoking 2nd stage check...")

                # ê²°ê³¼ ìš”ì•½ ìƒì„±
                result_summaries = []
                for msg_idx, msg in result_messages:
                    entity = msg.queryPlan.get("entity", "unknown") if msg.queryPlan else "unknown"
                    count = 0
                    if msg.queryResult:
                        if isinstance(msg.queryResult, dict):
                            count = msg.queryResult.get("totalCount", msg.queryResult.get("metadata", {}).get("rowsReturned", 0))
                    filters_str = ""
                    if msg.queryPlan and msg.queryPlan.get("filters"):
                        filters_str = ", ".join([f"{f.get('field')}={f.get('value')}" for f in msg.queryPlan.get("filters", [])[:2]])
                    result_summaries.append({"entity": entity, "count": count, "filters": filters_str})

                # 2ë‹¨ê³„ LLM íŒë‹¨ í˜¸ì¶œ
                needs_result_clarification = await query_planner.check_clarification_needed(
                    user_message=request.message,
                    result_summaries=result_summaries,
                    query_intent=query_intent
                )
                logger.info(f"[{request_id}] 2nd stage LLM decision: needs_result_clarification={needs_result_clarification}")

            if len(result_messages) > 1 and needs_result_clarification:
                # ë‹¤ì¤‘ ê²°ê³¼ + LLMì´ ëª¨í˜¸í•˜ë‹¤ê³  íŒë‹¨: clarification ìš”ì²­
                recent_results = result_messages[-5:]  # ìµœê·¼ 5ê°œë§Œ
                options = []
                indices = []

                for idx, (msg_idx, msg) in enumerate(reversed(recent_results)):
                    # ê²°ê³¼ ìš”ì•½ ë¼ë²¨ ìƒì„±
                    entity = msg.queryPlan.get("entity", "ë°ì´í„°") if msg.queryPlan else "ë°ì´í„°"
                    count = "?"
                    if msg.queryResult:
                        if isinstance(msg.queryResult, dict):
                            count = msg.queryResult.get("totalCount", msg.queryResult.get("metadata", {}).get("rowsReturned", "?"))
                        elif hasattr(msg.queryResult, "totalCount"):
                            count = msg.queryResult.totalCount
                    time_str = msg.timestamp[-8:-3] if msg.timestamp and len(msg.timestamp) >= 8 else ""

                    label = f"ì§ì „: {entity} {count}ê±´ ({time_str})" if idx == 0 else f"{entity} {count}ê±´ ({time_str})"
                    options.append(label)
                    indices.append(msg_idx)

                logger.info(f"[{request_id}] Multiple results found, requesting clarification")

                clarification_render_spec = {
                    "type": "clarification",
                    "clarification": {
                        "question": "ì–´ë–¤ ì¡°íšŒ ê²°ê³¼ë¥¼ í•„í„°ë§í• ê¹Œìš”?",
                        "options": options
                    },
                    "metadata": {
                        "requestId": request_id,
                        "targetResultIndices": indices,
                        "pendingFilters": query_plan.get("filters", []),
                        "generatedAt": datetime.utcnow().isoformat() + "Z"
                    }
                }

                return ChatResponse(
                    request_id=request_id,
                    render_spec=clarification_render_spec,
                    query_result=None,
                    query_plan={**query_plan, "needs_clarification": True, "requestId": request_id},
                    ai_message="ì–´ë–¤ ì¡°íšŒ ê²°ê³¼ë¥¼ í•„í„°ë§í• ê¹Œìš”?",
                    timestamp=datetime.utcnow().isoformat() + "Z"
                )

            # ê²°ê³¼ê°€ 1ê°œ ì´í•˜: í´ë¼ì´ì–¸íŠ¸ì—ì„œ í•„í„°ë§í•˜ë„ë¡ ì‘ë‹µ
            target_index = result_messages[-1][0] if result_messages else -1
            logger.info(f"[{request_id}] Single result, returning filter_local response (target: {target_index})")

            filter_local_render_spec = {
                "type": "filter_local",
                "filter": query_plan.get("filters", []),
                "targetResultIndex": target_index,
                "metadata": {
                    "requestId": request_id,
                    "generatedAt": datetime.utcnow().isoformat() + "Z"
                }
            }

            return ChatResponse(
                request_id=request_id,
                render_spec=filter_local_render_spec,
                query_result=None,
                query_plan={**query_plan, "requestId": request_id},
                ai_message="ì´ì „ ê²°ê³¼ì—ì„œ í•„í„°ë§í•©ë‹ˆë‹¤.",
                timestamp=datetime.utcnow().isoformat() + "Z"
            )
        elif query_intent == "aggregate_local":
            # í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ ì§‘ê³„: ì´ì „ ê²°ê³¼ì—ì„œ ì§‘ê³„
            logger.info(f"[{request_id}] Intent: aggregate_local, client-side aggregation")

            # entityê°€ ì—†ìœ¼ë©´ ì´ì „ queryPlanì—ì„œ ìƒì†
            if not query_plan.get("entity") and request.conversation_history:
                previous_plan = get_previous_query_plan(request.conversation_history)
                if previous_plan and previous_plan.get("entity"):
                    query_plan["entity"] = previous_plan["entity"]
                    logger.info(f"[{request_id}] Inherited entity from previous plan: {query_plan['entity']}")

            # ì´ì „ ê²°ê³¼ê°€ ìˆëŠ” ë©”ì‹œì§€ë“¤ ì°¾ê¸°
            result_messages = []
            if request.conversation_history:
                logger.info(f"[{request_id}] Checking {len(request.conversation_history)} messages in history")
                for i, msg in enumerate(request.conversation_history):
                    has_query_result = msg.queryResult is not None
                    if msg.role == "assistant" and msg.queryResult:
                        result_messages.append((i, msg))

            logger.info(f"[{request_id}] Found {len(result_messages)} result messages for aggregation")

            # ì§‘ê³„ ì •ë³´ ì¶”ì¶œ
            aggregations = query_plan.get("aggregations", [])
            if not aggregations:
                # ê¸°ë³¸ ì§‘ê³„: sum(amount)
                aggregations = [{"function": "sum", "field": "amount", "alias": "totalAmount", "displayLabel": "ê²°ì œ ê¸ˆì•¡ í•©ê³„", "currency": "USD"}]

            # 1ë‹¨ê³„: LLMì´ ëª¨í˜¸í•˜ë‹¤ê³  íŒë‹¨í–ˆëŠ”ì§€ í™•ì¸
            needs_result_clarification = query_plan.get("needs_result_clarification", False)
            logger.info(f"[{request_id}] 1st stage LLM decision (aggregate): needs_result_clarification={needs_result_clarification}")

            # 2ë‹¨ê³„: ë‹¤ì¤‘ ê²°ê³¼ + 1ë‹¨ê³„ê°€ Falseë©´ ìƒìœ„ ëª¨ë¸ë¡œ ì¬íŒë‹¨
            if len(result_messages) > 1 and not needs_result_clarification:
                logger.info(f"[{request_id}] Multiple results but 1st stage said no clarification, invoking 2nd stage check...")

                # ê²°ê³¼ ìš”ì•½ ìƒì„±
                result_summaries = []
                for msg_idx, msg in result_messages:
                    entity = msg.queryPlan.get("entity", "unknown") if msg.queryPlan else "unknown"
                    count = 0
                    if msg.queryResult:
                        if isinstance(msg.queryResult, dict):
                            count = msg.queryResult.get("totalCount", msg.queryResult.get("metadata", {}).get("rowsReturned", 0))
                    filters_str = ""
                    if msg.queryPlan and msg.queryPlan.get("filters"):
                        filters_str = ", ".join([f"{f.get('field')}={f.get('value')}" for f in msg.queryPlan.get("filters", [])[:2]])
                    result_summaries.append({"entity": entity, "count": count, "filters": filters_str})

                # 2ë‹¨ê³„ LLM íŒë‹¨ í˜¸ì¶œ
                needs_result_clarification = await query_planner.check_clarification_needed(
                    user_message=request.message,
                    result_summaries=result_summaries,
                    query_intent=query_intent
                )
                logger.info(f"[{request_id}] 2nd stage LLM decision (aggregate): needs_result_clarification={needs_result_clarification}")

            if len(result_messages) > 1 and needs_result_clarification:
                # ë‹¤ì¤‘ ê²°ê³¼ + LLMì´ ëª¨í˜¸í•˜ë‹¤ê³  íŒë‹¨: clarification ìš”ì²­
                recent_results = result_messages[-5:]  # ìµœê·¼ 5ê°œë§Œ
                options = []
                indices = []

                for idx, (msg_idx, msg) in enumerate(reversed(recent_results)):
                    entity = msg.queryPlan.get("entity", "ë°ì´í„°") if msg.queryPlan else "ë°ì´í„°"
                    count = "?"
                    if msg.queryResult:
                        if isinstance(msg.queryResult, dict):
                            count = msg.queryResult.get("totalCount", msg.queryResult.get("metadata", {}).get("rowsReturned", "?"))
                    time_str = msg.timestamp[-8:-3] if msg.timestamp and len(msg.timestamp) >= 8 else ""

                    label = f"ì§ì „: {entity} {count}ê±´ ({time_str})" if idx == 0 else f"{entity} {count}ê±´ ({time_str})"
                    options.append(label)
                    indices.append(msg_idx)

                logger.info(f"[{request_id}] Multiple results found, requesting clarification for aggregation")

                clarification_render_spec = {
                    "type": "clarification",
                    "clarification": {
                        "question": "ì–´ë–¤ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì§‘ê³„í• ê¹Œìš”?",
                        "options": options
                    },
                    "metadata": {
                        "requestId": request_id,
                        "targetResultIndices": indices,
                        "pendingAggregations": aggregations,
                        "aggregationType": "aggregate_local",
                        "generatedAt": datetime.utcnow().isoformat() + "Z"
                    }
                }

                return ChatResponse(
                    request_id=request_id,
                    render_spec=clarification_render_spec,
                    query_result=None,
                    query_plan={**query_plan, "needs_clarification": True, "requestId": request_id},
                    ai_message="ì–´ë–¤ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì§‘ê³„í• ê¹Œìš”?",
                    timestamp=datetime.utcnow().isoformat() + "Z"
                )

            # ê²°ê³¼ê°€ 1ê°œ ì´í•˜: í´ë¼ì´ì–¸íŠ¸ì—ì„œ ì§‘ê³„í•˜ë„ë¡ ì‘ë‹µ
            target_index = result_messages[-1][0] if result_messages else -1
            logger.info(f"[{request_id}] Single result, returning aggregate_local response (target: {target_index})")

            aggregate_local_render_spec = {
                "type": "aggregate_local",
                "aggregations": aggregations,
                "targetResultIndex": target_index,
                "metadata": {
                    "requestId": request_id,
                    "generatedAt": datetime.utcnow().isoformat() + "Z"
                }
            }

            return ChatResponse(
                request_id=request_id,
                render_spec=aggregate_local_render_spec,
                query_result=None,
                query_plan={**query_plan, "requestId": request_id},
                ai_message="ì´ì „ ê²°ê³¼ì—ì„œ ì§‘ê³„í•©ë‹ˆë‹¤.",
                timestamp=datetime.utcnow().isoformat() + "Z"
            )
        elif query_intent == "direct_answer":
            # LLMì´ ì§ì ‘ ë‹µë³€: DB ì¡°íšŒ ì—†ì´ í…ìŠ¤íŠ¸ ì‘ë‹µ
            direct_answer = query_plan.get("direct_answer", "")
            logger.info(f"[{request_id}] Intent: direct_answer, returning LLM response")

            if not direct_answer:
                direct_answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

            direct_answer_render_spec = {
                "type": "text",
                "title": "ë¶„ì„ ê²°ê³¼",
                "text": {
                    "content": direct_answer,
                    "format": "markdown"
                },
                "metadata": {
                    "requestId": request_id,
                    "generatedAt": datetime.utcnow().isoformat() + "Z"
                }
            }

            return ChatResponse(
                request_id=request_id,
                render_spec=direct_answer_render_spec,
                query_result=None,
                query_plan={**query_plan, "requestId": request_id},
                ai_message=direct_answer,
                timestamp=datetime.utcnow().isoformat() + "Z"
            )
        else:
            logger.info(f"[{request_id}] Intent: new_query, no filter merge")

        query_plan["requestId"] = request_id

        processing_info["stages"].append({
            "name": "query_plan_generation",
            "durationMs": int((datetime.utcnow() - stage_start).total_seconds() * 1000),
            "status": "success"
        })

        logger.info(f"[{request_id}] Final QueryPlan: {query_plan}")

        # Clarification í•„ìš” ì‹œ ì¿¼ë¦¬ ì‹¤í–‰ ì—†ì´ ëŒ€í™”í˜• ì§ˆë¬¸ ë°˜í™˜
        if query_plan.get("needs_clarification"):
            question = query_plan.get("clarification_question", "ì–´ë–¤ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
            logger.info(f"[{request_id}] Clarification needed: {question}")

            # ëŒ€í™”í˜• í…ìŠ¤íŠ¸ë¡œ ì‘ë‹µ (ë²„íŠ¼ ì—†ì´)
            clarification_render_spec = {
                "type": "text",
                "title": "ì¶”ê°€ ì •ë³´ í•„ìš”",
                "text": {
                    "content": question,
                    "format": "plain"
                },
                "metadata": {
                    "requestId": request_id,
                    "generatedAt": datetime.utcnow().isoformat() + "Z"
                }
            }

            clarification_query_result = {
                "requestId": request_id,
                "status": "pending",
                "data": {"rows": [], "aggregations": {}},
                "metadata": {
                    "executionTimeMs": int((datetime.utcnow() - start_time).total_seconds() * 1000),
                    "rowsReturned": 0,
                    "dataSource": "clarification_required"
                }
            }

            return ChatResponse(
                request_id=request_id,
                render_spec=clarification_render_spec,
                query_result=clarification_query_result,
                query_plan=query_plan,
                ai_message=question,
                timestamp=datetime.utcnow().isoformat() + "Z"
            )

        # Stage 2: Call Core API
        stage_start = datetime.utcnow()
        query_result = await call_core_api(query_plan)

        processing_info["stages"].append({
            "name": "core_api_call",
            "durationMs": int((datetime.utcnow() - stage_start).total_seconds() * 1000),
            "status": "success" if query_result.get("status") == "success" else "error"
        })

        logger.info(f"[{request_id}] Core API response status: {query_result.get('status')}")

        # Stage 3: QueryResult â†’ RenderSpec
        stage_start = datetime.utcnow()
        render_composer = get_render_composer()
        render_spec = render_composer.compose(query_result, query_plan, request.message)

        processing_info["stages"].append({
            "name": "render_spec_composition",
            "durationMs": int((datetime.utcnow() - stage_start).total_seconds() * 1000),
            "status": "success"
        })

        # Calculate total processing time
        total_time = int((datetime.utcnow() - start_time).total_seconds() * 1000)
        processing_info["totalDurationMs"] = total_time

        logger.info(f"[{request_id}] Completed in {total_time}ms")

        return ChatResponse(
            request_id=request_id,
            render_spec=render_spec,
            query_result=query_result,
            query_plan=query_plan,  # í›„ì† ì§ˆë¬¸ì—ì„œ ì´ì „ ì¿¼ë¦¬ ì¡°ê±´ ì°¸ì¡°ìš©
            ai_message=f"'{request.message}'ì— ëŒ€í•œ ê²°ê³¼ì…ë‹ˆë‹¤.",
            timestamp=datetime.utcnow().isoformat() + "Z"
        )

    except Exception as e:
        logger.error(f"[{request_id}] Error: {e}", exc_info=True)

        total_time = int((datetime.utcnow() - start_time).total_seconds() * 1000)
        processing_info["totalDurationMs"] = total_time
        processing_info["error"] = str(e)

        # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ RenderSpec ë°˜í™˜ (ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œìš©)
        error_render_spec = {
            "type": "text",
            "title": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            "text": {
                "content": f"## ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤\n\n"
                          f"**ìš”ì²­**: {request.message}\n\n"
                          f"**ì˜¤ë¥˜**: {str(e)}\n\n"
                          f"ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "format": "markdown",
                "sections": [
                    {
                        "type": "error",
                        "title": "ì˜¤ë¥˜ ì •ë³´",
                        "content": str(e)
                    }
                ]
            },
            "metadata": {
                "requestId": request_id,
                "generatedAt": datetime.utcnow().isoformat() + "Z"
            }
        }

        # ì—ëŸ¬ ì‹œ ë¹ˆ QueryResult ë°˜í™˜
        error_query_result = {
            "requestId": request_id,
            "status": "error",
            "data": {"rows": [], "aggregations": {}},
            "metadata": {
                "executionTimeMs": total_time,
                "rowsReturned": 0,
                "totalRows": 0,
                "dataSource": "error"
            },
            "error": {
                "code": "PROCESSING_ERROR",
                "message": str(e)
            }
        }

        # ì—ëŸ¬ ì‹œ ë¹ˆ QueryPlan ë°˜í™˜
        error_query_plan = {
            "entity": "",
            "operation": "list"
        }

        return ChatResponse(
            request_id=request_id,
            render_spec=error_render_spec,
            query_result=error_query_result,
            query_plan=error_query_plan,
            ai_message=f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            timestamp=datetime.utcnow().isoformat() + "Z"
        )


async def call_core_api(query_plan: Dict[str, Any]) -> Dict[str, Any]:
    """Core API í˜¸ì¶œ"""
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{CORE_API_URL}/api/v1/query/start",
                json=query_plan
            )

            # HTTP ì—ëŸ¬ê°€ ì•„ë‹Œ ë¹„ì¦ˆë‹ˆìŠ¤ ì—ëŸ¬ë„ ì²˜ë¦¬
            if response.status_code >= 400:
                error_body = response.json() if response.headers.get("content-type", "").startswith("application/json") else {}
                logger.warning(f"Core API returned {response.status_code}: {error_body}")
                return error_body if error_body else {
                    "status": "error",
                    "error": {
                        "code": f"HTTP_{response.status_code}",
                        "message": response.text
                    }
                }

            return response.json()

    except httpx.TimeoutException:
        logger.error("Core API timeout")
        return {
            "status": "error",
            "error": {
                "code": "TIMEOUT",
                "message": "Core API ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤."
            }
        }
    except httpx.HTTPError as e:
        logger.error(f"Core API HTTP error: {e}")
        return {
            "status": "error",
            "error": {
                "code": "CONNECTION_ERROR",
                "message": f"Core API ì—°ê²° ì˜¤ë¥˜: {str(e)}"
            }
        }


@router.get("/chat/test")
async def test_core_api():
    """Core API ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get(f"{CORE_API_URL}/api/v1/query/health")
            response.raise_for_status()
            return {
                "core_api_status": "reachable",
                "core_api_response": response.json()
            }
    except httpx.HTTPError as e:
        return {
            "core_api_status": "unreachable",
            "error": str(e)
        }


@router.get("/chat/config")
async def get_config():
    """í˜„ì¬ ì„¤ì • í™•ì¸ (ë””ë²„ê¹…ìš©)"""
    return {
        "core_api_url": CORE_API_URL,
        "openai_api_key_set": bool(os.getenv("OPENAI_API_KEY")),
        "anthropic_api_key_set": bool(os.getenv("ANTHROPIC_API_KEY")),
        "rag_enabled": os.getenv("RAG_ENABLED", "true").lower() == "true",
        "database_url_set": bool(os.getenv("DATABASE_URL")),
        "query_plan_validation": {
            "enabled": ENABLE_QUERY_PLAN_VALIDATION,
            "validator_provider": os.getenv("VALIDATOR_LLM_PROVIDER", "openai"),
            "validator_model": os.getenv("VALIDATOR_LLM_MODEL", "gpt-4o-mini"),
            "quality_threshold": float(os.getenv("VALIDATOR_QUALITY_THRESHOLD", "0.8")),
            "use_llm_validation": os.getenv("VALIDATOR_USE_LLM", "true").lower() == "true"
        },
        "step": "8-query-plan-validation"
    }


@router.get("/chat/rag/status")
async def get_rag_status():
    """RAG ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    try:
        rag_service = get_rag_service()
        doc_counts = await rag_service.get_document_count()

        return {
            "status": "available",
            "rag_enabled": os.getenv("RAG_ENABLED", "true").lower() == "true",
            "openai_configured": bool(os.getenv("OPENAI_API_KEY")),
            "document_counts": doc_counts,
            "total_documents": sum(doc_counts.values()) if doc_counts else 0
        }
    except Exception as e:
        return {
            "status": "unavailable",
            "error": str(e)
        }


@router.post("/chat/rag/search")
async def search_documents(query: str, k: int = 3):
    """RAG ë¬¸ì„œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    try:
        rag_service = get_rag_service()
        documents = await rag_service.search_docs(query=query, k=k)

        return {
            "query": query,
            "count": len(documents),
            "documents": [
                {
                    "id": doc.id,
                    "doc_type": doc.doc_type,
                    "title": doc.title,
                    "content": doc.content[:200] + "..." if len(doc.content) > 200 else doc.content,
                    "similarity": doc.similarity
                }
                for doc in documents
            ]
        }
    except Exception as e:
        return {
            "query": query,
            "error": str(e)
        }


# ============================================
# ëŒ€ìš©ëŸ‰ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸
# ============================================

class DownloadRequest(BaseModel):
    """ë‹¤ìš´ë¡œë“œ ìš”ì²­"""
    sql: str
    format: str = "csv"  # csv ë˜ëŠ” excel


@router.post("/chat/download")
async def download_query_result(request: DownloadRequest):
    """
    ëŒ€ìš©ëŸ‰ ì¿¼ë¦¬ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ

    - SQL ì¬ê²€ì¦ í›„ ì‹¤í–‰ (LIMIT ì—†ì´)
    - Streaming ì‘ë‹µìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨í™”
    """
    if not ENABLE_TEXT_TO_SQL:
        raise HTTPException(400, "Text-to-SQL mode is not enabled")

    from app.services.sql_validator import get_sql_validator
    from app.services.text_to_sql import get_text_to_sql_service

    # SQL ê²€ì¦ (ë³´ì•ˆ)
    validator = get_sql_validator()
    validation = validator.validate(request.sql)

    if not validation.is_valid:
        raise HTTPException(400, f"Invalid SQL: {', '.join(validation.issues)}")

    # LIMIT ì œê±° (ì „ì²´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ)
    unlimited_sql = re.sub(r'\bLIMIT\s+\d+', '', validation.sanitized_sql, flags=re.IGNORECASE)
    unlimited_sql = re.sub(r'\bOFFSET\s+\d+', '', unlimited_sql, flags=re.IGNORECASE)

    logger.info(f"Download request - Original SQL: {request.sql[:100]}...")
    logger.info(f"Download request - Unlimited SQL: {unlimited_sql[:100]}...")

    text_to_sql = get_text_to_sql_service()

    def generate_csv() -> Generator[str, None, None]:
        """CSV ìŠ¤íŠ¸ë¦¬ë° ìƒì„±ê¸°"""
        import psycopg
        from psycopg.rows import dict_row

        try:
            with text_to_sql._get_readonly_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute(unlimited_sql)

                    # í—¤ë” ì¶œë ¥
                    columns = [desc[0] for desc in cur.description]
                    output = io.StringIO()
                    writer = csv.writer(output)
                    writer.writerow(columns)
                    yield output.getvalue()

                    # ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬ (1000ê±´ì”©)
                    batch_size = 1000
                    row_count = 0
                    while True:
                        rows = cur.fetchmany(batch_size)
                        if not rows:
                            break

                        output = io.StringIO()
                        writer = csv.writer(output)
                        for row in rows:
                            # datetime ë³€í™˜
                            processed_row = []
                            for value in row.values() if hasattr(row, 'values') else row:
                                if hasattr(value, 'isoformat'):
                                    processed_row.append(value.isoformat())
                                else:
                                    processed_row.append(value)
                            writer.writerow(processed_row)
                            row_count += 1

                        yield output.getvalue()

                    logger.info(f"Download completed: {row_count} rows")

        except psycopg.Error as e:
            logger.error(f"Download SQL execution failed: {e}")
            yield f"Error: {str(e)}"

    # íŒŒì¼ëª… ìƒì„±
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    filename = f"query_result_{timestamp}.csv"

    return StreamingResponse(
        generate_csv(),
        media_type="text/csv; charset=utf-8",
        headers={
            "Content-Disposition": f"attachment; filename={filename}",
            "X-Content-Type-Options": "nosniff"
        }
    )


# ============================================
# Text-to-SQL ëª¨ë“œ í•¸ë“¤ëŸ¬
# ============================================

async def handle_text_to_sql(
    request: ChatRequest,
    request_id: str,
    start_time: datetime
) -> ChatResponse:
    """
    Text-to-SQL ëª¨ë“œ ì²˜ë¦¬

    AIê°€ ì§ì ‘ SQLì„ ìƒì„±í•˜ê³  ì½ê¸° ì „ìš© DBì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    logger.info(f"[{request_id}] Text-to-SQL mode: processing")

    try:
        text_to_sql = get_text_to_sql_service()

        # ëŒ€í™” ì´ë ¥ ë³€í™˜ (Text-to-SQL í˜•ì‹)
        sql_history = build_sql_history(request.conversation_history)

        # SQL ìƒì„± ë° ì‹¤í–‰
        result = await text_to_sql.query(
            question=request.message,
            conversation_history=sql_history,
            retry_on_error=True
        )

        # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
        total_time_ms = int((datetime.utcnow() - start_time).total_seconds() * 1000)

        if result["success"]:
            # ì„±ê³µ: ë°ì´í„°ë¥¼ RenderSpecìœ¼ë¡œ ë³€í™˜
            render_spec = compose_sql_render_spec(result, request.message)
            query_result = {
                "requestId": request_id,
                "status": "success",
                "data": {
                    "rows": result["data"],
                    "aggregations": {}
                },
                "metadata": {
                    "executionTimeMs": int(result.get("executionTimeMs") or 0),
                    "rowsReturned": result["rowCount"],
                    "totalRows": result["rowCount"],
                    "dataSource": "text_to_sql"
                }
            }
        else:
            # ì‹¤íŒ¨: ì—ëŸ¬ RenderSpec
            render_spec = {
                "type": "text",
                "title": "ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜",
                "text": {
                    "content": f"## ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤\n\n"
                              f"**ì§ˆë¬¸**: {request.message}\n\n"
                              f"**ì˜¤ë¥˜**: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}\n\n"
                              f"**ìƒì„±ëœ SQL**:\n```sql\n{result.get('sql', 'N/A')}\n```",
                    "format": "markdown"
                },
                "metadata": {
                    "requestId": request_id,
                    "generatedAt": datetime.utcnow().isoformat() + "Z",
                    "mode": "text_to_sql"
                }
            }
            query_result = {
                "requestId": request_id,
                "status": "error",
                "data": {"rows": [], "aggregations": {}},
                "metadata": {
                    "executionTimeMs": total_time_ms,
                    "rowsReturned": 0,
                    "dataSource": "text_to_sql"
                },
                "error": {
                    "code": "SQL_EXECUTION_ERROR",
                    "message": result.get("error", "Unknown error")
                }
            }

        logger.info(f"[{request_id}] Text-to-SQL completed: success={result['success']}, rows={result['rowCount']}")

        return ChatResponse(
            request_id=request_id,
            render_spec=render_spec,
            query_result=query_result,
            query_plan={
                "mode": "text_to_sql",
                "sql": result.get("sql"),
                "requestId": request_id
            },
            ai_message=f"'{request.message}'ì— ëŒ€í•œ ê²°ê³¼ì…ë‹ˆë‹¤." if result["success"] else "ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
            timestamp=datetime.utcnow().isoformat() + "Z"
        )

    except Exception as e:
        logger.error(f"[{request_id}] Text-to-SQL error: {e}", exc_info=True)
        total_time_ms = int((datetime.utcnow() - start_time).total_seconds() * 1000)

        error_render_spec = {
            "type": "text",
            "title": "ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ",
            "text": {
                "content": f"## Text-to-SQL ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤\n\n"
                          f"**ìš”ì²­**: {request.message}\n\n"
                          f"**ì˜¤ë¥˜**: {str(e)}\n\n"
                          f"ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                "format": "markdown"
            },
            "metadata": {
                "requestId": request_id,
                "generatedAt": datetime.utcnow().isoformat() + "Z",
                "mode": "text_to_sql"
            }
        }

        return ChatResponse(
            request_id=request_id,
            render_spec=error_render_spec,
            query_result={
                "requestId": request_id,
                "status": "error",
                "data": {"rows": [], "aggregations": {}},
                "metadata": {"executionTimeMs": total_time_ms, "rowsReturned": 0}
            },
            query_plan={"mode": "text_to_sql", "error": str(e)},
            ai_message=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            timestamp=datetime.utcnow().isoformat() + "Z"
        )


def build_sql_history(conversation_history: Optional[List[ChatMessageItem]]) -> List[Dict[str, str]]:
    """ëŒ€í™” ì´ë ¥ì„ Text-to-SQL í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if not conversation_history:
        return []

    sql_history = []
    for msg in conversation_history[-10:]:  # ìµœê·¼ 10ê°œë§Œ
        entry = {
            "role": msg.role,
            "content": msg.content
        }
        # assistant ë©”ì‹œì§€ì— SQL ì •ë³´ê°€ ìˆìœ¼ë©´ í¬í•¨
        if msg.role == "assistant" and msg.queryPlan:
            if msg.queryPlan.get("mode") == "text_to_sql" and msg.queryPlan.get("sql"):
                entry["sql"] = msg.queryPlan.get("sql")
        sql_history.append(entry)

    return sql_history


def compose_sql_render_spec(result: Dict[str, Any], question: str) -> Dict[str, Any]:
    """SQL ì‹¤í–‰ ê²°ê³¼ë¥¼ RenderSpecìœ¼ë¡œ ë³€í™˜

    - 1000ê±´ ì´ˆê³¼: ë‹¤ìš´ë¡œë“œ RenderSpec (í…Œì´ë¸” í‘œì‹œ ì•ˆí•¨)
    - 1000ê±´ ì´í•˜: ë¯¸ë¦¬ë³´ê¸° 10ê±´ + ì „ì²´ë³´ê¸° ëª¨ë‹¬
    """
    data = result.get("data", [])
    row_count = result.get("rowCount", 0)
    total_count = result.get("totalCount") or row_count
    is_truncated = result.get("isTruncated", False)
    PREVIEW_LIMIT = 10  # ë¯¸ë¦¬ë³´ê¸° í–‰ ìˆ˜
    MAX_DISPLAY_ROWS = 1000  # í™”ë©´ í‘œì‹œ ìµœëŒ€ ê±´ìˆ˜

    # 1000ê±´ ì´ˆê³¼: ë‹¤ìš´ë¡œë“œ RenderSpec ë°˜í™˜
    if is_truncated:
        return {
            "type": "download",
            "title": "ëŒ€ìš©ëŸ‰ ë°ì´í„° ì¡°íšŒ",
            "download": {
                "totalRows": total_count,
                "maxDisplayRows": MAX_DISPLAY_ROWS,
                "message": f"ì¡°íšŒ ê²°ê³¼ê°€ {total_count:,}ê±´ìœ¼ë¡œ í™”ë©´ í‘œì‹œ ì œí•œ({MAX_DISPLAY_ROWS:,}ê±´)ì„ ì´ˆê³¼í•©ë‹ˆë‹¤.",
                "sql": result.get("sql"),
                "formats": ["csv"]
            },
            "metadata": {
                "sql": result.get("sql"),
                "executionTimeMs": result.get("executionTimeMs"),
                "mode": "text_to_sql"
            }
        }

    if not data:
        return {
            "type": "text",
            "title": "ì¡°íšŒ ê²°ê³¼",
            "text": {
                "content": "ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "format": "plain"
            },
            "metadata": {
                "sql": result.get("sql"),
                "executionTimeMs": result.get("executionTimeMs")
            }
        }

    # ë‹¨ì¼ í–‰ + ì§‘ê³„ ê²°ê³¼ì²˜ëŸ¼ ë³´ì´ë©´ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
    if row_count == 1 and len(data[0]) <= 3:
        row = data[0]
        # í‚¤-ê°’ ìŒìœ¼ë¡œ í‘œì‹œ
        content_parts = []
        for key, value in row.items():
            # ê¸ˆì•¡ í¬ë§·íŒ…
            if isinstance(value, (int, float)) and any(kw in key.lower() for kw in ["amount", "sum", "total", "count", "avg"]):
                if value >= 1000000:
                    formatted = f"â‚©{value:,.0f} ({value/1000000:.2f}M)"
                elif value >= 1000:
                    formatted = f"â‚©{value:,.0f}"
                else:
                    formatted = f"{value:,.2f}" if isinstance(value, float) else f"{value:,}"
                content_parts.append(f"**{key}**: {formatted}")
            else:
                content_parts.append(f"**{key}**: {value}")

        return {
            "type": "text",
            "title": "ì§‘ê³„ ê²°ê³¼",
            "text": {
                "content": "\n".join(content_parts),
                "format": "markdown"
            },
            "metadata": {
                "sql": result.get("sql"),
                "executionTimeMs": result.get("executionTimeMs"),
                "mode": "text_to_sql"
            }
        }

    # ë‹¤ì¤‘ í–‰: í…Œì´ë¸”ë¡œ í‘œì‹œ (ë¯¸ë¦¬ë³´ê¸° ëª¨ë“œ)
    if data:
        columns = list(data[0].keys())
        column_defs = []
        for col in columns:
            col_def = {
                "key": col,  # UI TableRenderer í˜¸í™˜
                "label": col.replace("_", " ").title(),  # TableRenderer expects 'label'
                "field": col,
                "headerName": col.replace("_", " ").title()
            }
            # ê¸ˆì•¡ í•„ë“œ ê°ì§€
            if any(kw in col.lower() for kw in ["amount", "fee", "net", "total", "price"]):
                col_def["type"] = "currency"
                col_def["currencyCode"] = "KRW"
            # ë‚ ì§œ í•„ë“œ ê°ì§€
            elif any(kw in col.lower() for kw in ["date", "time", "at", "created", "updated"]):
                col_def["type"] = "datetime"
            column_defs.append(col_def)

        # ë¯¸ë¦¬ë³´ê¸°ìš© ë°ì´í„° (ìµœëŒ€ PREVIEW_LIMITê±´)
        preview_data = data[:PREVIEW_LIMIT]
        has_more = row_count > PREVIEW_LIMIT

        # íƒ€ì´í‹€: ë¯¸ë¦¬ë³´ê¸°ì¸ ê²½ìš° í‘œì‹œ
        if has_more:
            title = f"ì¡°íšŒ ê²°ê³¼ ({row_count}ê±´ ì¤‘ {PREVIEW_LIMIT}ê±´ ë¯¸ë¦¬ë³´ê¸°)"
        else:
            title = f"ì¡°íšŒ ê²°ê³¼ ({row_count}ê±´)"

        return {
            "type": "table",
            "title": title,
            "table": {
                "columns": column_defs,
                "data": preview_data,  # ë¯¸ë¦¬ë³´ê¸°ë§Œ ì „ì†¡
                "dataRef": "data.rows",
                "actions": [
                    {"action": "fullscreen", "label": "ì „ì²´ë³´ê¸°"},
                    {"action": "export-csv", "label": "CSV ë‹¤ìš´ë¡œë“œ"}
                ],
                "pagination": {
                    "enabled": False,  # ë¯¸ë¦¬ë³´ê¸°ì—ì„œëŠ” í˜ì´ì§€ë„¤ì´ì…˜ ë¹„í™œì„±í™”
                    "pageSize": PREVIEW_LIMIT,
                    "totalRows": row_count
                }
            },
            # ì „ì²´ ë°ì´í„°ëŠ” ë³„ë„ë¡œ ì €ì¥ (ëª¨ë‹¬ì—ì„œ ì‚¬ìš©)
            "fullData": data if has_more else None,
            "preview": {
                "enabled": has_more,
                "previewRows": PREVIEW_LIMIT,
                "totalRows": row_count,
                "message": f"ì „ì²´ {row_count}ê±´ ì¤‘ {PREVIEW_LIMIT}ê±´ë§Œ í‘œì‹œë©ë‹ˆë‹¤. ì „ì²´ë³´ê¸° ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”."
            },
            "metadata": {
                "sql": result.get("sql"),
                "executionTimeMs": result.get("executionTimeMs"),
                "mode": "text_to_sql"
            }
        }

    return {
        "type": "text",
        "title": "ê²°ê³¼",
        "text": {
            "content": f"ì¡°íšŒ ì™„ë£Œ: {row_count}ê±´",
            "format": "plain"
        }
    }
