"""
Chat API - Step 6: LangChain + Natural Language Processing
ÏûêÏó∞Ïñ¥ ‚Üí QueryPlan ‚Üí Core API ‚Üí RenderSpec

Text-to-SQL Î™®Îìú Ï∂îÍ∞Ä:
SQL_ENABLE_TEXT_TO_SQL=true ÏÑ§Ï†ï Ïãú AIÍ∞Ä ÏßÅÏ†ë SQLÏùÑ ÏÉùÏÑ±ÌïòÏó¨ ÏùΩÍ∏∞ Ï†ÑÏö© DBÏóêÏÑú Ïã§Ìñâ
"""

from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any, List, Generator, Tuple
import httpx
import logging
import os
import re
import uuid
import csv
import io
from datetime import datetime


# ============================================
# Ï∞∏Ï°∞ ÌëúÌòÑ Í∞êÏßÄ (Ïó∞ÏÜç ÎåÄÌôî WHERE Ï°∞Í±¥ Î≥ëÌï©Ïö©)
# ============================================

def detect_reference_expression(message: str) -> Tuple[bool, str]:
    """
    ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄÏóêÏÑú Ï∞∏Ï°∞ ÌëúÌòÑ Í∞êÏßÄ

    Ï∞∏Ï°∞ ÌëúÌòÑÏù¥ ÏûàÏúºÎ©¥ Ïù¥Ï†Ñ WHERE Ï°∞Í±¥ÏùÑ Ïú†ÏßÄÌï¥Ïïº Ìï®ÏùÑ ÏùòÎØ∏

    Args:
        message: ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄ

    Returns:
        (is_refinement, ref_type) ÌäúÌîå
        - is_refinement: TrueÎ©¥ Ïù¥Ï†Ñ Ï°∞Í±¥ Ïú†ÏßÄ ÌïÑÏöî
        - ref_type: 'filter' (ÌïÑÌÑ∞ Ï∂îÍ∞Ä), 'new' (ÏÉà ÏøºÎ¶¨), 'none' (Ìï¥ÎãπÏóÜÏùå)
    """
    # ÌïÑÌÑ∞/ÏÑ∏Î∂ÑÌôî Ìå®ÌÑ¥ (Ïù¥Ï†Ñ Í≤∞Í≥º Ï∞∏Ï°∞)
    FILTER_PATTERNS = [
        r'Ïù¥\s*Ï§ëÏóê?',           # "Ïù¥Ï§ëÏóê", "Ïù¥ Ï§ëÏóê"
        r'Ïó¨Í∏∞ÏÑú',               # "Ïó¨Í∏∞ÏÑú"
        r'Í∑∏\s*Ï§ë',              # "Í∑∏Ï§ë", "Í∑∏ Ï§ë"
        r'ÏßÅÏ†Ñ',                 # "ÏßÅÏ†Ñ"
        r'Î∞©Í∏à',                 # "Î∞©Í∏à"
        r'ÏúÑ\s*Í≤∞Í≥º',            # "ÏúÑ Í≤∞Í≥º", "ÏúÑÍ≤∞Í≥º"
        r'Ïïû\s*(ÏÑú|ÏóêÏÑú)',        # "ÏïûÏÑú", "ÏïûÏóêÏÑú"
        r'Ìï¥Îãπ\s*Îç∞Ïù¥ÌÑ∞',         # "Ìï¥Îãπ Îç∞Ïù¥ÌÑ∞"
        r'Ïù¥\s*Í≤∞Í≥º',            # "Ïù¥ Í≤∞Í≥º"
        r'Ï†Ä\s*Ï§ëÏóê?',           # "Ï†ÄÏ§ëÏóê", "Ï†Ä Ï§ëÏóê"
        r'Í±∞Í∏∞ÏÑú',               # "Í±∞Í∏∞ÏÑú"
    ]

    # ÏÉà ÏøºÎ¶¨ Ìå®ÌÑ¥ (Ïù¥Ï†Ñ Ï°∞Í±¥ Î¨¥Ïãú)
    NEW_QUERY_PATTERNS = [
        r'ÏÉàÎ°ú\s*.{0,10}Ï°∞Ìöå',   # "ÏÉàÎ°ú Ï°∞Ìöå", "ÏÉàÎ°ú ÌôòÎ∂à ÎÇ¥Ïó≠ Ï°∞Ìöå"
        r'Îã§Ïãú\s*.{0,10}Ï°∞Ìöå',   # "Îã§Ïãú Ï°∞Ìöå", "Îã§Ïãú Í≤∞Ï†ú Ï°∞Ìöå"
        r'Ï≤òÏùåÎ∂ÄÌÑ∞',             # "Ï≤òÏùåÎ∂ÄÌÑ∞"
        r'ÏÉà\s*ÏøºÎ¶¨',            # "ÏÉà ÏøºÎ¶¨"
        r'Ï†ÑÏ≤¥\s*Îã§Ïãú',          # "Ï†ÑÏ≤¥ Îã§Ïãú"
    ]

    # ÏÉà ÏøºÎ¶¨ Ìå®ÌÑ¥ Î®ºÏ†Ä Ï≤¥ÌÅ¨ (Ïö∞ÏÑ†ÏàúÏúÑ ÎÜíÏùå)
    for pattern in NEW_QUERY_PATTERNS:
        if re.search(pattern, message, re.IGNORECASE):
            return (False, 'new')

    # ÌïÑÌÑ∞ Ìå®ÌÑ¥ Ï≤¥ÌÅ¨
    for pattern in FILTER_PATTERNS:
        if re.search(pattern, message, re.IGNORECASE):
            return (True, 'filter')

    return (False, 'none')

# Text-to-SQL Î™®Îìú ÌîåÎûòÍ∑∏
ENABLE_TEXT_TO_SQL = os.getenv("SQL_ENABLE_TEXT_TO_SQL", "false").lower() == "true"


def to_camel(string: str) -> str:
    """snake_caseÎ•º camelCaseÎ°ú Î≥ÄÌôò"""
    components = string.split('_')
    return components[0] + ''.join(x.title() for x in components[1:])


def summarize_query_plan(query_plan: Dict[str, Any]) -> str:
    """QueryPlanÏùÑ Í∞ÑÎã®Ìïú ÏöîÏïΩ Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò"""
    parts = []

    entity = query_plan.get("entity", "")
    if entity:
        parts.append(entity)

    # ÌïÑÌÑ∞ ÏöîÏïΩ
    filters = query_plan.get("filters", [])
    if filters:
        filter_strs = [f"{f.get('field')} {f.get('operator')} {f.get('value')}" for f in filters]
        parts.append(f"filters:[{', '.join(filter_strs)}]")

    # limit
    if query_plan.get("limit"):
        parts.append(f"limit:{query_plan['limit']}")

    # orderBy
    order_by = query_plan.get("orderBy", [])
    if order_by:
        order_strs = [f"{o.get('field')} {o.get('direction', 'asc')}" for o in order_by]
        parts.append(f"orderBy:[{', '.join(order_strs)}]")

    return ", ".join(parts) if parts else "[ÏøºÎ¶¨ ÏóÜÏùå]"


def build_conversation_context(history: List["ChatMessageItem"]) -> str:
    """Ïù¥Ï†Ñ ÎåÄÌôîÎ•º ÌîÑÎ°¨ÌîÑÌä∏Ïö© ÌÖçÏä§Ìä∏Î°ú Î≥ÄÌôò (Îã§Ï§ë Í≤∞Í≥º ÏÉÅÌô© Î™ÖÏãú Ìè¨Ìï®)"""
    if not history:
        return ""

    context = "## Ïù¥Ï†Ñ ÎåÄÌôî Ïª®ÌÖçÏä§Ìä∏\n\n"

    # ============================================
    # [NEW] Îã§Ï§ë Í≤∞Í≥º ÏÉÅÌô© Î™ÖÏãú ÏÑπÏÖò
    # ============================================
    result_messages = []
    for i, msg in enumerate(history):
        if msg.role == "assistant" and msg.queryResult:
            entity = msg.queryPlan.get("entity", "unknown") if msg.queryPlan else "unknown"
            count = msg.queryResult.get("totalCount", 0)
            # ÌïÑÌÑ∞ Ï†ïÎ≥¥ÎèÑ Ï∂îÍ∞Ä (Í∞ôÏùÄ entityÎùºÎèÑ Ï°∞Í±¥Ïù¥ Îã§Î•º Ïàò ÏûàÏùå)
            filters = msg.queryPlan.get("filters", []) if msg.queryPlan else []
            filter_desc = ""
            if filters:
                filter_strs = [f"{f.get('field')}={f.get('value')}" for f in filters[:2]]
                filter_desc = f" ({', '.join(filter_strs)})"
            result_messages.append({
                "index": i,
                "entity": entity,
                "count": count,
                "filter_desc": filter_desc,
                "is_latest": False
            })

    if result_messages:
        result_messages[-1]["is_latest"] = True  # ÎßàÏßÄÎßâÏù¥ ÏßÅÏ†Ñ Í≤∞Í≥º

        context += "### üìä ÌòÑÏû¨ ÏÑ∏ÏÖòÏùò Ï°∞Ìöå Í≤∞Í≥º ÌòÑÌô©\n"
        for r in result_messages:
            marker = "üëâ (ÏßÅÏ†Ñ)" if r["is_latest"] else ""
            context += f"- Í≤∞Í≥º #{r['index']}: {r['entity']} {r['count']}Í±¥{r['filter_desc']} {marker}\n"

        if len(result_messages) > 1:
            # Îã§Ï§ë Í≤∞Í≥º Í≤ΩÍ≥† - LLMÏù¥ Ï£ºÎ™©ÌïòÎèÑÎ°ù
            entities = set(r["entity"] for r in result_messages)
            if len(entities) > 1:
                context += f"\n‚ö†Ô∏è **Îã§Î•∏ Ï¢ÖÎ•òÏùò Í≤∞Í≥ºÍ∞Ä {len(result_messages)}Í∞ú ÏûàÏäµÎãàÎã§** ({', '.join(entities)})\n"
                context += "‚Üí ÏÇ¨Ïö©ÏûêÍ∞Ä ÌäπÏ†ï Í≤∞Í≥ºÎ•º ÏßÄÏ†ïÌïòÏßÄ ÏïäÏúºÎ©¥ needs_result_clarification=true Í∂åÏû•\n"
            else:
                context += f"\nüìå ÎèôÏùº ÏóîÌã∞Ìã∞({list(entities)[0]}) Í≤∞Í≥ºÍ∞Ä {len(result_messages)}Í∞ú ÏûàÏäµÎãàÎã§ (Ï°∞Í±¥Ïù¥ Îã§Î¶Ñ).\n"
                context += "‚Üí Ï∞∏Ï°∞ ÌëúÌòÑ ÏóÜÏù¥ ÏßëÍ≥Ñ/ÌïÑÌÑ∞ ÏöîÏ≤≠ Ïãú needs_result_clarification=true Í≥†Î†§\n"
        context += "\n"

    # ============================================
    # ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨ (Í∏∞Ï°¥ Ïú†ÏßÄ)
    # ============================================
    context += "### ÎåÄÌôî ÌûàÏä§ÌÜ†Î¶¨\n"
    for msg in history[-5:]:
        if msg.role == 'user':
            context += f"ÏÇ¨Ïö©Ïûê: {msg.content}\n"
        else:
            # queryPlan ÏöîÏïΩ Ìè¨Ìï®
            if msg.queryPlan:
                plan_summary = summarize_query_plan(msg.queryPlan)
                context += f"Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏: [ÏøºÎ¶¨: {plan_summary}]\n"
            else:
                context += f"Ïñ¥ÏãúÏä§ÌÑ¥Ìä∏: [Í≤∞Í≥º ÌëúÏãúÎê®]\n"

            # ÏßëÍ≥Ñ Í≤∞Í≥ºÍ∞í Ìè¨Ìï® (Ï§ëÏöî: ÌõÑÏÜç Í≥ÑÏÇ∞Ïö©)
            if msg.renderSpec and msg.renderSpec.get("type") == "text":
                text_content = msg.renderSpec.get("text", {}).get("content", "")
                if text_content and ("Ìï©Í≥Ñ" in text_content or "$" in text_content or "Ïõê" in text_content):
                    context += f"  ‚Üí ÏßëÍ≥Ñ Í≤∞Í≥º: {text_content}\n"

    # ============================================
    # ÌõÑÏÜç ÏßàÎ¨∏ Ï≤òÎ¶¨ Í∑úÏπô (Í∞úÏÑ†)
    # ============================================
    context += "\n### ÌõÑÏÜç ÏßàÎ¨∏ Ï≤òÎ¶¨ Í∑úÏπô\n"
    context += "1. 'Ïù¥Ï§ëÏóê', 'Ïó¨Í∏∞ÏÑú', 'ÏßÅÏ†Ñ', 'Î∞©Í∏à' Îì± Ï∞∏Ï°∞ ÌëúÌòÑ ‚Üí **ÏßÅÏ†Ñ Í≤∞Í≥º ÏÇ¨Ïö©**, needs_result_clarification=false\n"
    context += "2. Ï∞∏Ï°∞ ÌëúÌòÑ ÏóÜÏù¥ ÏßëÍ≥Ñ/ÌïÑÌÑ∞ ÏöîÏ≤≠ + Îã§Ï§ë Í≤∞Í≥º ‚Üí needs_result_clarification=true Í≥†Î†§\n"
    context += "3. ÌõÑÏÜç ÏßàÎ¨∏ÏóêÏÑúÎäî **Ïù¥Ï†Ñ ÏóîÌã∞Ìã∞ Ïú†ÏßÄ** (Îã§Î•∏ ÏóîÌã∞Ìã∞Î°ú Î≥ÄÍ≤Ω Í∏àÏßÄ)\n"
    context += "4. Ïù¥Ï†Ñ ÏßëÍ≥Ñ Í≤∞Í≥ºÏóê ÎåÄÌïú ÏÇ∞Ïà† Ïó∞ÏÇ∞ ‚Üí query_intent=direct_answer\n"
    return context


def get_previous_query_plan(history: List["ChatMessageItem"]) -> Optional[Dict[str, Any]]:
    """Ïù¥Ï†Ñ ÎåÄÌôîÏóêÏÑú ÎßàÏßÄÎßâ queryPlan Ï∂îÏ∂ú"""
    if not history:
        return None

    # Ïó≠ÏàúÏúºÎ°ú ÌÉêÏÉâÌïòÏó¨ Í∞ÄÏû• ÏµúÍ∑º assistantÏùò queryPlan Ï∞æÍ∏∞
    for msg in reversed(history):
        if msg.role == 'assistant' and msg.queryPlan:
            return msg.queryPlan
    return None


def extract_previous_results(history: List["ChatMessageItem"]) -> List[Dict[str, Any]]:
    """Ïù¥Ï†Ñ ÎåÄÌôîÏóêÏÑú Ï°∞Ìöå/ÏßëÍ≥Ñ Í≤∞Í≥º ÏöîÏïΩ Ï∂îÏ∂ú (Intent ClassificationÏö©)

    Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞ Í∞íÎèÑ Ï∂îÏ∂úÌïòÏó¨ LLMÏù¥ Í≥ÑÏÇ∞Ìï† Ïàò ÏûàÎèÑÎ°ù Ìï®
    """
    results = []
    if not history:
        return results

    for i, msg in enumerate(history):
        if msg.role == "assistant":
            result_info = {
                "index": i,
                "entity": None,
                "count": 0,
                "aggregation": None,
                "data_summary": None,  # Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞ ÏöîÏïΩ
                "total_amount": None   # Í∏àÏï° Ìï©Í≥Ñ (ÏûàÎäî Í≤ΩÏö∞)
            }

            # QueryResultÍ∞Ä ÏûàÏúºÎ©¥ Ï°∞Ìöå Í≤∞Í≥º
            if msg.queryResult:
                logger.info(f"[extract_previous_results] msg #{i} has queryResult with keys: {list(msg.queryResult.keys())}")
                result_info["count"] = msg.queryResult.get("totalCount", 0)
                if msg.queryPlan:
                    result_info["entity"] = msg.queryPlan.get("entity", "unknown")

                # Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Í∏àÏï° Ìï©Í≥Ñ Ï∂îÏ∂ú
                data_obj = msg.queryResult.get("data", {})
                # data is an object with 'rows' property according to query-result.schema.json
                rows = data_obj.get("rows", []) if isinstance(data_obj, dict) else []
                logger.info(f"[extract_previous_results] msg #{i} rows length: {len(rows) if rows else 0}")

                if rows:
                    # amount ÌïÑÎìúÍ∞Ä ÏûàÏúºÎ©¥ Ìï©Í≥Ñ Í≥ÑÏÇ∞
                    amounts = []
                    for row_idx, row in enumerate(rows):
                        if isinstance(row, dict):
                            logger.info(f"[extract_previous_results] msg #{i} row #{row_idx} keys: {list(row.keys())}")
                            # amount, totalAmount, Í∏àÏï° Îì± Îã§ÏñëÌïú ÌïÑÎìúÎ™Ö Ï≤¥ÌÅ¨
                            for field in ["amount", "totalAmount", "total_amount", "price", "Í∏àÏï°"]:
                                if field in row and row[field] is not None:
                                    try:
                                        amounts.append(float(row[field]))
                                        logger.info(f"[extract_previous_results] msg #{i} row #{row_idx} found {field}={row[field]}")
                                    except (ValueError, TypeError) as e:
                                        logger.info(f"[extract_previous_results] msg #{i} row #{row_idx} error converting {field}: {e}")
                                        pass
                                    break
                        else:
                            logger.info(f"[extract_previous_results] msg #{i} row #{row_idx} is not a dict: {type(row)}")

                    if amounts:
                        result_info["total_amount"] = sum(amounts)
                        result_info["data_summary"] = f"Í∏àÏï° Ìï©Í≥Ñ: ${result_info['total_amount']:,.0f} ({len(amounts)}Í±¥)"
                        logger.info(f"[extract_previous_results] msg #{i} extracted total_amount: ${result_info['total_amount']:,.0f} from {len(amounts)} amounts")
                    else:
                        logger.info(f"[extract_previous_results] msg #{i} no amounts found in {len(rows)} rows")

            # RenderSpecÏù¥ text ÌÉÄÏûÖÏù¥Î©¥ ÏßëÍ≥Ñ Í≤∞Í≥ºÏùº Ïàò ÏûàÏùå
            if msg.renderSpec and msg.renderSpec.get("type") == "text":
                text_content = msg.renderSpec.get("text", {}).get("content", "")
                if text_content:
                    result_info["aggregation"] = text_content

                    # ÌÖçÏä§Ìä∏ÏóêÏÑú Í∏àÏï° Ï∂îÏ∂ú (Ïö∞ÏÑ†ÏàúÏúÑ: Í¥ÑÌò∏ Ïïà Ï†ÑÏ≤¥ Í∏àÏï° > Ï∂ïÏïΩ Í∏àÏï°)
                    if result_info["total_amount"] is None:
                        # 1ÏàúÏúÑ: Í¥ÑÌò∏ ÏïàÏùò Ï†ÑÏ≤¥ Í∏àÏï° (Ïòà: "$2.88M ($2,878,000)" ‚Üí 2878000)
                        full_amount_match = re.search(r'\(\$?([\d,]+)\)', text_content)
                        if full_amount_match:
                            try:
                                result_info["total_amount"] = float(full_amount_match.group(1).replace(',', ''))
                                logger.info(f"[extract_previous_results] Extracted full amount from parens: ${result_info['total_amount']:,.0f}")
                            except ValueError:
                                pass

                        # 2ÏàúÏúÑ: M/K Ï†ëÎØ∏ÏÇ¨ Ï≤òÎ¶¨ (Ïòà: "$2.88M" ‚Üí 2880000)
                        if result_info["total_amount"] is None:
                            abbrev_match = re.search(r'\$?([\d,]+(?:\.\d+)?)\s*([MK])', text_content)
                            if abbrev_match:
                                try:
                                    value = float(abbrev_match.group(1).replace(',', ''))
                                    suffix = abbrev_match.group(2)
                                    if suffix == 'M':
                                        value *= 1_000_000
                                    elif suffix == 'K':
                                        value *= 1_000
                                    result_info["total_amount"] = value
                                    logger.info(f"[extract_previous_results] Extracted abbreviated amount: ${result_info['total_amount']:,.0f}")
                                except ValueError:
                                    pass

                        # 3ÏàúÏúÑ: ÏùºÎ∞ò Í∏àÏï° (Ïòà: "$1,234,567")
                        if result_info["total_amount"] is None:
                            simple_match = re.search(r'\$?([\d,]+(?:\.\d+)?)', text_content)
                            if simple_match:
                                try:
                                    result_info["total_amount"] = float(simple_match.group(1).replace(',', ''))
                                    logger.info(f"[extract_previous_results] Extracted simple amount: ${result_info['total_amount']:,.0f}")
                                except ValueError:
                                    pass

            # Ï°∞Ìöå Í≤∞Í≥ºÎÇò ÏßëÍ≥Ñ Í≤∞Í≥ºÍ∞Ä ÏûàÏúºÎ©¥ Ï∂îÍ∞Ä
            if result_info["count"] > 0 or result_info["aggregation"]:
                results.append(result_info)
                logger.info(f"[extract_previous_results] Added result #{len(results)}: entity={result_info['entity']}, count={result_info['count']}, total_amount={result_info['total_amount']}")

    logger.info(f"[extract_previous_results] Total results extracted: {len(results)}")
    return results


def merge_filters(previous_plan: Dict[str, Any], new_plan: Dict[str, Any]) -> Dict[str, Any]:
    """Ïù¥Ï†Ñ ÌïÑÌÑ∞ÏôÄ ÏÉà ÌïÑÌÑ∞Î•º Î≥ëÌï©"""
    if not previous_plan:
        return new_plan

    # clarification ÏöîÏ≤≠Ïù¥Î©¥ Î≥ëÌï©ÌïòÏßÄ ÏïäÏùå
    if new_plan.get("needs_clarification"):
        return new_plan

    # Ïù¥Ï†Ñ ÌïÑÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞
    prev_filters = previous_plan.get("filters", [])
    new_filters = new_plan.get("filters", [])

    # ÏÉà ÌïÑÌÑ∞Ïùò ÌïÑÎìúÎ™Ö Î™©Î°ù
    new_filter_fields = {f.get("field") for f in new_filters}

    # Ïù¥Ï†Ñ ÌïÑÌÑ∞ Ï§ë ÏÉà ÌïÑÌÑ∞Ïóê ÏóÜÎäî Í≤ÉÎßå Î≥ëÌï© (Ï§ëÎ≥µ ÌïÑÎìú Î∞©ÏßÄ)
    merged_filters = list(new_filters)  # ÏÉà ÌïÑÌÑ∞ Ïö∞ÏÑ†
    for prev_filter in prev_filters:
        if prev_filter.get("field") not in new_filter_fields:
            merged_filters.append(prev_filter)

    # Î≥ëÌï©Îêú Í≤∞Í≥º
    merged_plan = dict(new_plan)
    if merged_filters:
        merged_plan["filters"] = merged_filters

    # Ïù¥Ï†Ñ entity Ïú†ÏßÄ (ÏÉà planÏóê entityÍ∞Ä ÏóÜÏúºÎ©¥)
    if not merged_plan.get("entity") and previous_plan.get("entity"):
        merged_plan["entity"] = previous_plan["entity"]

    # Ïù¥Ï†Ñ limit Ïú†ÏßÄ (ÏÉà planÏù¥ Í∏∞Î≥∏Í∞í 10Ïù¥Î©¥)
    if merged_plan.get("limit") == 10 and previous_plan.get("limit"):
        merged_plan["limit"] = previous_plan["limit"]

    return merged_plan

from app.services.query_planner import get_query_planner, IntentType
from app.services.render_composer import get_render_composer
from app.services.rag_service import get_rag_service

# Text-to-SQL Î™®ÎìúÏö© import (Ï°∞Í±¥Î∂Ä)
if ENABLE_TEXT_TO_SQL:
    from app.services.text_to_sql import get_text_to_sql_service

logger = logging.getLogger(__name__)
logger.info(f"Text-to-SQL mode: {'ENABLED' if ENABLE_TEXT_TO_SQL else 'DISABLED'}")

router = APIRouter()

# Configuration
CORE_API_URL = os.getenv("CORE_API_URL", "http://localhost:8080")
ENABLE_QUERY_PLAN_VALIDATION = os.getenv("ENABLE_QUERY_PLAN_VALIDATION", "true").lower() == "true"


class ChatMessageItem(BaseModel):
    """ÎåÄÌôî Î©îÏãúÏßÄ ÏïÑÏù¥ÌÖú"""
    id: str
    role: str  # 'user' | 'assistant'
    content: str
    timestamp: str
    status: Optional[str] = None
    renderSpec: Optional[Dict[str, Any]] = None
    queryResult: Optional[Dict[str, Any]] = None
    queryPlan: Optional[Dict[str, Any]] = None  # Ïù¥Ï†Ñ ÏøºÎ¶¨ Ï°∞Í±¥ Ï†ÄÏû•Ïö©


class ChatRequest(BaseModel):
    """Ï±ÑÌåÖ ÏöîÏ≤≠"""
    message: str
    conversation_id: Optional[str] = None
    session_id: Optional[str] = Field(default=None, alias="sessionId")
    conversation_history: Optional[List[ChatMessageItem]] = Field(default=None, alias="conversationHistory")

    class Config:
        populate_by_name = True


class ChatResponse(BaseModel):
    """Ï±ÑÌåÖ ÏùëÎãµ - UI ÌÉÄÏûÖÍ≥º ÏùºÏπò"""
    request_id: str = Field(alias="requestId")
    render_spec: Dict[str, Any] = Field(alias="renderSpec")
    query_result: Optional[Dict[str, Any]] = Field(default=None, alias="queryResult")  # filter_local Ïãú None Í∞ÄÎä•
    query_plan: Dict[str, Any] = Field(alias="queryPlan")  # Ïù¥Î≤à ÏøºÎ¶¨ Ï°∞Í±¥ (ÌõÑÏÜç ÏßàÎ¨∏Ïö©)
    ai_message: Optional[str] = Field(default=None, alias="aiMessage")
    timestamp: str

    class Config:
        populate_by_name = True


@router.post("/chat", response_model=ChatResponse, response_model_by_alias=True)
async def chat(request: ChatRequest):
    """
    Step 6: LangChain Í∏∞Î∞ò ÏûêÏó∞Ïñ¥ Ï≤òÎ¶¨

    Flow (Í∏∞Ï°¥ QueryPlan Î™®Îìú):
    1. ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄ ÏàòÏã†
    2. QueryPlannerServiceÎ°ú ÏûêÏó∞Ïñ¥ ‚Üí QueryPlan Î≥ÄÌôò
    3. Core API Ìò∏Ï∂ú
    4. RenderComposerServiceÎ°ú QueryResult ‚Üí RenderSpec Î≥ÄÌôò
    5. RenderSpec Î∞òÌôò

    Flow (Text-to-SQL Î™®Îìú, SQL_ENABLE_TEXT_TO_SQL=true):
    1. ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄ ÏàòÏã†
    2. TextToSqlServiceÎ°ú ÏûêÏó∞Ïñ¥ ‚Üí SQL Î≥ÄÌôò
    3. SQL Í≤ÄÏ¶ù (SqlValidator)
    4. ÏùΩÍ∏∞ Ï†ÑÏö© DBÏóêÏÑú ÏßÅÏ†ë Ïã§Ìñâ
    5. Í≤∞Í≥ºÎ•º RenderSpecÏúºÎ°ú Î≥ÄÌôò
    """
    start_time = datetime.utcnow()
    conversation_id = request.conversation_id or str(uuid.uuid4())
    request_id = f"req-{uuid.uuid4().hex[:8]}"

    logger.info(f"[{request_id}] Received message: {request.message}")

    processing_info = {
        "requestId": request_id,
        "stages": []
    }

    # ========================================
    # Text-to-SQL Î™®Îìú Î∂ÑÍ∏∞
    # ========================================
    if ENABLE_TEXT_TO_SQL:
        return await handle_text_to_sql(request, request_id, start_time)

    try:
        # Stage 0: Intent Classification (2Îã®Í≥Ñ Î∂ÑÎ•ò)
        stage_start = datetime.utcnow()
        query_planner = get_query_planner()

        # ÎåÄÌôî Ïª®ÌÖçÏä§Ìä∏ ÎπåÎìú
        conversation_context = None
        previous_results = []
        if request.conversation_history:
            conversation_context = build_conversation_context(request.conversation_history)
            previous_results = extract_previous_results(request.conversation_history)
            logger.info(f"[{request_id}] Using conversation context with {len(request.conversation_history)} messages")
            logger.info(f"[{request_id}] Found {len(previous_results)} previous results for intent classification")

        # 1Îã®Í≥Ñ: Intent Î∂ÑÎ•ò (Í∞ÄÎ≤ºÏö¥ Î™®Îç∏Î°ú Îπ†Î•¥Í≤å)
        intent_result = await query_planner.classify_intent(
            request.message,
            conversation_context or "",
            previous_results
        )
        logger.info(f"[{request_id}] Intent classification: {intent_result.intent.value}, confidence={intent_result.confidence:.2f}")

        # direct_answerÎ©¥ Î∞îÎ°ú ÏùëÎãµ Î∞òÌôò (QueryPlan ÏÉùÏÑ± Ïä§ÌÇµ)
        if intent_result.intent == IntentType.DIRECT_ANSWER and intent_result.direct_answer_text:
            logger.info(f"[{request_id}] Direct answer detected, skipping QueryPlan generation")
            logger.info(f"[{request_id}] Direct answer text: {intent_result.direct_answer_text}")

            return ChatResponse(
                request_id=request_id,
                query_plan={
                    "query_intent": "direct_answer",
                    "requestId": request_id
                },
                query_result=None,
                render_spec={
                    "type": "text",
                    "text": {
                        "content": intent_result.direct_answer_text,
                        "format": "markdown"
                    },
                    "metadata": {
                        "intent": "direct_answer",
                        "confidence": intent_result.confidence,
                        "reasoning": intent_result.reasoning
                    }
                },
                timestamp=datetime.utcnow().isoformat() + "Z"
            )

        processing_info["stages"].append({
            "name": "Intent Classification",
            "duration": (datetime.utcnow() - stage_start).total_seconds() * 1000,
            "result": intent_result.intent.value
        })

        # Stage 1: Natural Language ‚Üí QueryPlan
        stage_start = datetime.utcnow()

        query_plan = await query_planner.generate_query_plan(
            request.message,
            conversation_context=conversation_context,
            enable_validation=ENABLE_QUERY_PLAN_VALIDATION
        )

        # LLMÏù¥ ÌåêÎã®Ìïú ÏùòÎèÑÏóê Îî∞Îùº ÌïÑÌÑ∞ Î≥ëÌï© Í≤∞Ï†ï
        query_intent = query_plan.get("query_intent", "new_query")
        logger.info(f"[{request_id}] Query intent: {query_intent}")

        if query_intent == "refine_previous":
            if request.conversation_history:
                previous_plan = get_previous_query_plan(request.conversation_history)
                if previous_plan:
                    logger.info(f"[{request_id}] Intent: refine_previous, merging with previous filters")
                    logger.info(f"[{request_id}] Previous plan: {previous_plan}")
                    query_plan = merge_filters(previous_plan, query_plan)
                    logger.info(f"[{request_id}] Merged plan: {query_plan}")
        elif query_intent == "filter_local":
            # ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÇ¨Ïù¥Îìú ÌïÑÌÑ∞ÎßÅ: Core API Ìò∏Ï∂ú ÏóÜÏù¥ ÌïÑÌÑ∞ Ï°∞Í±¥Îßå Î∞òÌôò
            logger.info(f"[{request_id}] Intent: filter_local, client-side filtering")

            # entityÍ∞Ä ÏóÜÏúºÎ©¥ Ïù¥Ï†Ñ queryPlanÏóêÏÑú ÏÉÅÏÜç
            if not query_plan.get("entity") and request.conversation_history:
                previous_plan = get_previous_query_plan(request.conversation_history)
                if previous_plan and previous_plan.get("entity"):
                    query_plan["entity"] = previous_plan["entity"]
                    logger.info(f"[{request_id}] Inherited entity from previous plan: {query_plan['entity']}")

            # Ïù¥Ï†Ñ Í≤∞Í≥ºÍ∞Ä ÏûàÎäî Î©îÏãúÏßÄÎì§ Ï∞æÍ∏∞
            result_messages = []
            if request.conversation_history:
                logger.info(f"[{request_id}] Checking {len(request.conversation_history)} messages in history")
                for i, msg in enumerate(request.conversation_history):
                    has_query_result = msg.queryResult is not None
                    logger.info(f"[{request_id}] Message {i}: role={msg.role}, hasQueryResult={has_query_result}")
                    if msg.role == "assistant" and msg.queryResult:
                        result_messages.append((i, msg))

            logger.info(f"[{request_id}] Found {len(result_messages)} result messages")

            # 1Îã®Í≥Ñ: LLMÏù¥ Î™®Ìò∏ÌïòÎã§Í≥† ÌåêÎã®ÌñàÎäîÏßÄ ÌôïÏù∏
            needs_result_clarification = query_plan.get("needs_result_clarification", False)
            logger.info(f"[{request_id}] 1st stage LLM decision: needs_result_clarification={needs_result_clarification}")

            # 2Îã®Í≥Ñ: Îã§Ï§ë Í≤∞Í≥º + 1Îã®Í≥ÑÍ∞Ä FalseÎ©¥ ÏÉÅÏúÑ Î™®Îç∏Î°ú Ïû¨ÌåêÎã®
            if len(result_messages) > 1 and not needs_result_clarification:
                logger.info(f"[{request_id}] Multiple results but 1st stage said no clarification, invoking 2nd stage check...")

                # Í≤∞Í≥º ÏöîÏïΩ ÏÉùÏÑ±
                result_summaries = []
                for msg_idx, msg in result_messages:
                    entity = msg.queryPlan.get("entity", "unknown") if msg.queryPlan else "unknown"
                    count = 0
                    if msg.queryResult:
                        if isinstance(msg.queryResult, dict):
                            count = msg.queryResult.get("totalCount", msg.queryResult.get("metadata", {}).get("rowsReturned", 0))
                    filters_str = ""
                    if msg.queryPlan and msg.queryPlan.get("filters"):
                        filters_str = ", ".join([f"{f.get('field')}={f.get('value')}" for f in msg.queryPlan.get("filters", [])[:2]])
                    result_summaries.append({"entity": entity, "count": count, "filters": filters_str})

                # 2Îã®Í≥Ñ LLM ÌåêÎã® Ìò∏Ï∂ú
                needs_result_clarification = await query_planner.check_clarification_needed(
                    user_message=request.message,
                    result_summaries=result_summaries,
                    query_intent=query_intent
                )
                logger.info(f"[{request_id}] 2nd stage LLM decision: needs_result_clarification={needs_result_clarification}")

            if len(result_messages) > 1 and needs_result_clarification:
                # Îã§Ï§ë Í≤∞Í≥º + LLMÏù¥ Î™®Ìò∏ÌïòÎã§Í≥† ÌåêÎã®: clarification ÏöîÏ≤≠
                recent_results = result_messages[-5:]  # ÏµúÍ∑º 5Í∞úÎßå
                options = []
                indices = []

                for idx, (msg_idx, msg) in enumerate(reversed(recent_results)):
                    # Í≤∞Í≥º ÏöîÏïΩ ÎùºÎ≤® ÏÉùÏÑ±
                    entity = msg.queryPlan.get("entity", "Îç∞Ïù¥ÌÑ∞") if msg.queryPlan else "Îç∞Ïù¥ÌÑ∞"
                    count = "?"
                    if msg.queryResult:
                        if isinstance(msg.queryResult, dict):
                            count = msg.queryResult.get("totalCount", msg.queryResult.get("metadata", {}).get("rowsReturned", "?"))
                        elif hasattr(msg.queryResult, "totalCount"):
                            count = msg.queryResult.totalCount
                    time_str = msg.timestamp[-8:-3] if msg.timestamp and len(msg.timestamp) >= 8 else ""

                    label = f"ÏßÅÏ†Ñ: {entity} {count}Í±¥ ({time_str})" if idx == 0 else f"{entity} {count}Í±¥ ({time_str})"
                    options.append(label)
                    indices.append(msg_idx)

                logger.info(f"[{request_id}] Multiple results found, requesting clarification")

                clarification_render_spec = {
                    "type": "clarification",
                    "clarification": {
                        "question": "Ïñ¥Îñ§ Ï°∞Ìöå Í≤∞Í≥ºÎ•º ÌïÑÌÑ∞ÎßÅÌï†ÍπåÏöî?",
                        "options": options
                    },
                    "metadata": {
                        "requestId": request_id,
                        "targetResultIndices": indices,
                        "pendingFilters": query_plan.get("filters", []),
                        "generatedAt": datetime.utcnow().isoformat() + "Z"
                    }
                }

                return ChatResponse(
                    request_id=request_id,
                    render_spec=clarification_render_spec,
                    query_result=None,
                    query_plan={**query_plan, "needs_clarification": True, "requestId": request_id},
                    ai_message="Ïñ¥Îñ§ Ï°∞Ìöå Í≤∞Í≥ºÎ•º ÌïÑÌÑ∞ÎßÅÌï†ÍπåÏöî?",
                    timestamp=datetime.utcnow().isoformat() + "Z"
                )

            # Í≤∞Í≥ºÍ∞Ä 1Í∞ú Ïù¥Ìïò: ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÏóêÏÑú ÌïÑÌÑ∞ÎßÅÌïòÎèÑÎ°ù ÏùëÎãµ
            target_index = result_messages[-1][0] if result_messages else -1
            logger.info(f"[{request_id}] Single result, returning filter_local response (target: {target_index})")

            filter_local_render_spec = {
                "type": "filter_local",
                "filter": query_plan.get("filters", []),
                "targetResultIndex": target_index,
                "metadata": {
                    "requestId": request_id,
                    "generatedAt": datetime.utcnow().isoformat() + "Z"
                }
            }

            return ChatResponse(
                request_id=request_id,
                render_spec=filter_local_render_spec,
                query_result=None,
                query_plan={**query_plan, "requestId": request_id},
                ai_message="Ïù¥Ï†Ñ Í≤∞Í≥ºÏóêÏÑú ÌïÑÌÑ∞ÎßÅÌï©ÎãàÎã§.",
                timestamp=datetime.utcnow().isoformat() + "Z"
            )
        elif query_intent == "aggregate_local":
            # ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ÏÇ¨Ïù¥Îìú ÏßëÍ≥Ñ: Ïù¥Ï†Ñ Í≤∞Í≥ºÏóêÏÑú ÏßëÍ≥Ñ
            logger.info(f"[{request_id}] Intent: aggregate_local, client-side aggregation")

            # entityÍ∞Ä ÏóÜÏúºÎ©¥ Ïù¥Ï†Ñ queryPlanÏóêÏÑú ÏÉÅÏÜç
            if not query_plan.get("entity") and request.conversation_history:
                previous_plan = get_previous_query_plan(request.conversation_history)
                if previous_plan and previous_plan.get("entity"):
                    query_plan["entity"] = previous_plan["entity"]
                    logger.info(f"[{request_id}] Inherited entity from previous plan: {query_plan['entity']}")

            # Ïù¥Ï†Ñ Í≤∞Í≥ºÍ∞Ä ÏûàÎäî Î©îÏãúÏßÄÎì§ Ï∞æÍ∏∞
            result_messages = []
            if request.conversation_history:
                logger.info(f"[{request_id}] Checking {len(request.conversation_history)} messages in history")
                for i, msg in enumerate(request.conversation_history):
                    has_query_result = msg.queryResult is not None
                    if msg.role == "assistant" and msg.queryResult:
                        result_messages.append((i, msg))

            logger.info(f"[{request_id}] Found {len(result_messages)} result messages for aggregation")

            # ÏßëÍ≥Ñ Ï†ïÎ≥¥ Ï∂îÏ∂ú
            aggregations = query_plan.get("aggregations", [])
            if not aggregations:
                # Í∏∞Î≥∏ ÏßëÍ≥Ñ: sum(amount)
                aggregations = [{"function": "sum", "field": "amount", "alias": "totalAmount", "displayLabel": "Í≤∞Ï†ú Í∏àÏï° Ìï©Í≥Ñ", "currency": "USD"}]

            # 1Îã®Í≥Ñ: LLMÏù¥ Î™®Ìò∏ÌïòÎã§Í≥† ÌåêÎã®ÌñàÎäîÏßÄ ÌôïÏù∏
            needs_result_clarification = query_plan.get("needs_result_clarification", False)
            logger.info(f"[{request_id}] 1st stage LLM decision (aggregate): needs_result_clarification={needs_result_clarification}")

            # 2Îã®Í≥Ñ: Îã§Ï§ë Í≤∞Í≥º + 1Îã®Í≥ÑÍ∞Ä FalseÎ©¥ ÏÉÅÏúÑ Î™®Îç∏Î°ú Ïû¨ÌåêÎã®
            if len(result_messages) > 1 and not needs_result_clarification:
                logger.info(f"[{request_id}] Multiple results but 1st stage said no clarification, invoking 2nd stage check...")

                # Í≤∞Í≥º ÏöîÏïΩ ÏÉùÏÑ±
                result_summaries = []
                for msg_idx, msg in result_messages:
                    entity = msg.queryPlan.get("entity", "unknown") if msg.queryPlan else "unknown"
                    count = 0
                    if msg.queryResult:
                        if isinstance(msg.queryResult, dict):
                            count = msg.queryResult.get("totalCount", msg.queryResult.get("metadata", {}).get("rowsReturned", 0))
                    filters_str = ""
                    if msg.queryPlan and msg.queryPlan.get("filters"):
                        filters_str = ", ".join([f"{f.get('field')}={f.get('value')}" for f in msg.queryPlan.get("filters", [])[:2]])
                    result_summaries.append({"entity": entity, "count": count, "filters": filters_str})

                # 2Îã®Í≥Ñ LLM ÌåêÎã® Ìò∏Ï∂ú
                needs_result_clarification = await query_planner.check_clarification_needed(
                    user_message=request.message,
                    result_summaries=result_summaries,
                    query_intent=query_intent
                )
                logger.info(f"[{request_id}] 2nd stage LLM decision (aggregate): needs_result_clarification={needs_result_clarification}")

            if len(result_messages) > 1 and needs_result_clarification:
                # Îã§Ï§ë Í≤∞Í≥º + LLMÏù¥ Î™®Ìò∏ÌïòÎã§Í≥† ÌåêÎã®: clarification ÏöîÏ≤≠
                recent_results = result_messages[-5:]  # ÏµúÍ∑º 5Í∞úÎßå
                options = []
                indices = []

                for idx, (msg_idx, msg) in enumerate(reversed(recent_results)):
                    entity = msg.queryPlan.get("entity", "Îç∞Ïù¥ÌÑ∞") if msg.queryPlan else "Îç∞Ïù¥ÌÑ∞"
                    count = "?"
                    if msg.queryResult:
                        if isinstance(msg.queryResult, dict):
                            count = msg.queryResult.get("totalCount", msg.queryResult.get("metadata", {}).get("rowsReturned", "?"))
                    time_str = msg.timestamp[-8:-3] if msg.timestamp and len(msg.timestamp) >= 8 else ""

                    label = f"ÏßÅÏ†Ñ: {entity} {count}Í±¥ ({time_str})" if idx == 0 else f"{entity} {count}Í±¥ ({time_str})"
                    options.append(label)
                    indices.append(msg_idx)

                logger.info(f"[{request_id}] Multiple results found, requesting clarification for aggregation")

                clarification_render_spec = {
                    "type": "clarification",
                    "clarification": {
                        "question": "Ïñ¥Îñ§ Îç∞Ïù¥ÌÑ∞Î•º Í∏∞Ï§ÄÏúºÎ°ú ÏßëÍ≥ÑÌï†ÍπåÏöî?",
                        "options": options
                    },
                    "metadata": {
                        "requestId": request_id,
                        "targetResultIndices": indices,
                        "pendingAggregations": aggregations,
                        "aggregationType": "aggregate_local",
                        "generatedAt": datetime.utcnow().isoformat() + "Z"
                    }
                }

                return ChatResponse(
                    request_id=request_id,
                    render_spec=clarification_render_spec,
                    query_result=None,
                    query_plan={**query_plan, "needs_clarification": True, "requestId": request_id},
                    ai_message="Ïñ¥Îñ§ Îç∞Ïù¥ÌÑ∞Î•º Í∏∞Ï§ÄÏúºÎ°ú ÏßëÍ≥ÑÌï†ÍπåÏöî?",
                    timestamp=datetime.utcnow().isoformat() + "Z"
                )

            # Í≤∞Í≥ºÍ∞Ä 1Í∞ú Ïù¥Ìïò: ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÏóêÏÑú ÏßëÍ≥ÑÌïòÎèÑÎ°ù ÏùëÎãµ
            target_index = result_messages[-1][0] if result_messages else -1
            logger.info(f"[{request_id}] Single result, returning aggregate_local response (target: {target_index})")

            aggregate_local_render_spec = {
                "type": "aggregate_local",
                "aggregations": aggregations,
                "targetResultIndex": target_index,
                "metadata": {
                    "requestId": request_id,
                    "generatedAt": datetime.utcnow().isoformat() + "Z"
                }
            }

            return ChatResponse(
                request_id=request_id,
                render_spec=aggregate_local_render_spec,
                query_result=None,
                query_plan={**query_plan, "requestId": request_id},
                ai_message="Ïù¥Ï†Ñ Í≤∞Í≥ºÏóêÏÑú ÏßëÍ≥ÑÌï©ÎãàÎã§.",
                timestamp=datetime.utcnow().isoformat() + "Z"
            )
        elif query_intent == "direct_answer":
            # LLMÏù¥ ÏßÅÏ†ë ÎãµÎ≥Ä: DB Ï°∞Ìöå ÏóÜÏù¥ ÌÖçÏä§Ìä∏ ÏùëÎãµ
            direct_answer = query_plan.get("direct_answer", "")
            logger.info(f"[{request_id}] Intent: direct_answer, returning LLM response")

            if not direct_answer:
                direct_answer = "Ï£ÑÏÜ°Ìï©ÎãàÎã§. ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±ÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§."

            direct_answer_render_spec = {
                "type": "text",
                "title": "Î∂ÑÏÑù Í≤∞Í≥º",
                "text": {
                    "content": direct_answer,
                    "format": "markdown"
                },
                "metadata": {
                    "requestId": request_id,
                    "generatedAt": datetime.utcnow().isoformat() + "Z"
                }
            }

            return ChatResponse(
                request_id=request_id,
                render_spec=direct_answer_render_spec,
                query_result=None,
                query_plan={**query_plan, "requestId": request_id},
                ai_message=direct_answer,
                timestamp=datetime.utcnow().isoformat() + "Z"
            )
        else:
            logger.info(f"[{request_id}] Intent: new_query, no filter merge")

        query_plan["requestId"] = request_id

        processing_info["stages"].append({
            "name": "query_plan_generation",
            "durationMs": int((datetime.utcnow() - stage_start).total_seconds() * 1000),
            "status": "success"
        })

        logger.info(f"[{request_id}] Final QueryPlan: {query_plan}")

        # Clarification ÌïÑÏöî Ïãú ÏøºÎ¶¨ Ïã§Ìñâ ÏóÜÏù¥ ÎåÄÌôîÌòï ÏßàÎ¨∏ Î∞òÌôò
        if query_plan.get("needs_clarification"):
            question = query_plan.get("clarification_question", "Ïñ¥Îñ§ Îç∞Ïù¥ÌÑ∞Î•º Ï°∞ÌöåÌïòÏãúÍ≤†ÏäµÎãàÍπå?")
            logger.info(f"[{request_id}] Clarification needed: {question}")

            # ÎåÄÌôîÌòï ÌÖçÏä§Ìä∏Î°ú ÏùëÎãµ (Î≤ÑÌäº ÏóÜÏù¥)
            clarification_render_spec = {
                "type": "text",
                "title": "Ï∂îÍ∞Ä Ï†ïÎ≥¥ ÌïÑÏöî",
                "text": {
                    "content": question,
                    "format": "plain"
                },
                "metadata": {
                    "requestId": request_id,
                    "generatedAt": datetime.utcnow().isoformat() + "Z"
                }
            }

            clarification_query_result = {
                "requestId": request_id,
                "status": "pending",
                "data": {"rows": [], "aggregations": {}},
                "metadata": {
                    "executionTimeMs": int((datetime.utcnow() - start_time).total_seconds() * 1000),
                    "rowsReturned": 0,
                    "dataSource": "clarification_required"
                }
            }

            return ChatResponse(
                request_id=request_id,
                render_spec=clarification_render_spec,
                query_result=clarification_query_result,
                query_plan=query_plan,
                ai_message=question,
                timestamp=datetime.utcnow().isoformat() + "Z"
            )

        # Stage 2: Call Core API
        stage_start = datetime.utcnow()
        query_result = await call_core_api(query_plan)

        processing_info["stages"].append({
            "name": "core_api_call",
            "durationMs": int((datetime.utcnow() - stage_start).total_seconds() * 1000),
            "status": "success" if query_result.get("status") == "success" else "error"
        })

        logger.info(f"[{request_id}] Core API response status: {query_result.get('status')}")

        # Stage 3: QueryResult ‚Üí RenderSpec
        stage_start = datetime.utcnow()
        render_composer = get_render_composer()
        render_spec = render_composer.compose(query_result, query_plan, request.message)

        processing_info["stages"].append({
            "name": "render_spec_composition",
            "durationMs": int((datetime.utcnow() - stage_start).total_seconds() * 1000),
            "status": "success"
        })

        # Calculate total processing time
        total_time = int((datetime.utcnow() - start_time).total_seconds() * 1000)
        processing_info["totalDurationMs"] = total_time

        logger.info(f"[{request_id}] Completed in {total_time}ms")

        return ChatResponse(
            request_id=request_id,
            render_spec=render_spec,
            query_result=query_result,
            query_plan=query_plan,  # ÌõÑÏÜç ÏßàÎ¨∏ÏóêÏÑú Ïù¥Ï†Ñ ÏøºÎ¶¨ Ï°∞Í±¥ Ï∞∏Ï°∞Ïö©
            ai_message=f"'{request.message}'Ïóê ÎåÄÌïú Í≤∞Í≥ºÏûÖÎãàÎã§.",
            timestamp=datetime.utcnow().isoformat() + "Z"
        )

    except Exception as e:
        logger.error(f"[{request_id}] Error: {e}", exc_info=True)

        total_time = int((datetime.utcnow() - start_time).total_seconds() * 1000)
        processing_info["totalDurationMs"] = total_time
        processing_info["error"] = str(e)

        # ÏóêÎü¨ Î∞úÏÉù ÏãúÏóêÎèÑ RenderSpec Î∞òÌôò (ÏóêÎü¨ Î©îÏãúÏßÄ ÌëúÏãúÏö©)
        error_render_spec = {
            "type": "text",
            "title": "Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò Î∞úÏÉù",
            "text": {
                "content": f"## ÏöîÏ≤≠ Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§\n\n"
                          f"**ÏöîÏ≤≠**: {request.message}\n\n"
                          f"**Ïò§Î•ò**: {str(e)}\n\n"
                          f"Ïû†Ïãú ÌõÑ Îã§Ïãú ÏãúÎèÑÌï¥Ï£ºÏÑ∏Ïöî.",
                "format": "markdown",
                "sections": [
                    {
                        "type": "error",
                        "title": "Ïò§Î•ò Ï†ïÎ≥¥",
                        "content": str(e)
                    }
                ]
            },
            "metadata": {
                "requestId": request_id,
                "generatedAt": datetime.utcnow().isoformat() + "Z"
            }
        }

        # ÏóêÎü¨ Ïãú Îπà QueryResult Î∞òÌôò
        error_query_result = {
            "requestId": request_id,
            "status": "error",
            "data": {"rows": [], "aggregations": {}},
            "metadata": {
                "executionTimeMs": total_time,
                "rowsReturned": 0,
                "totalRows": 0,
                "dataSource": "error"
            },
            "error": {
                "code": "PROCESSING_ERROR",
                "message": str(e)
            }
        }

        # ÏóêÎü¨ Ïãú Îπà QueryPlan Î∞òÌôò
        error_query_plan = {
            "entity": "",
            "operation": "list"
        }

        return ChatResponse(
            request_id=request_id,
            render_spec=error_render_spec,
            query_result=error_query_result,
            query_plan=error_query_plan,
            ai_message=f"ÏöîÏ≤≠ Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}",
            timestamp=datetime.utcnow().isoformat() + "Z"
        )


async def call_core_api(query_plan: Dict[str, Any]) -> Dict[str, Any]:
    """Core API Ìò∏Ï∂ú"""
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                f"{CORE_API_URL}/api/v1/query/start",
                json=query_plan
            )

            # HTTP ÏóêÎü¨Í∞Ä ÏïÑÎãå ÎπÑÏ¶àÎãàÏä§ ÏóêÎü¨ÎèÑ Ï≤òÎ¶¨
            if response.status_code >= 400:
                error_body = response.json() if response.headers.get("content-type", "").startswith("application/json") else {}
                logger.warning(f"Core API returned {response.status_code}: {error_body}")
                return error_body if error_body else {
                    "status": "error",
                    "error": {
                        "code": f"HTTP_{response.status_code}",
                        "message": response.text
                    }
                }

            return response.json()

    except httpx.TimeoutException:
        logger.error("Core API timeout")
        return {
            "status": "error",
            "error": {
                "code": "TIMEOUT",
                "message": "Core API ÏöîÏ≤≠ ÏãúÍ∞ÑÏù¥ Ï¥àÍ≥ºÎêòÏóàÏäµÎãàÎã§."
            }
        }
    except httpx.HTTPError as e:
        logger.error(f"Core API HTTP error: {e}")
        return {
            "status": "error",
            "error": {
                "code": "CONNECTION_ERROR",
                "message": f"Core API Ïó∞Í≤∞ Ïò§Î•ò: {str(e)}"
            }
        }


@router.get("/chat/test")
async def test_core_api():
    """Core API Ïó∞Í≤∞ ÌÖåÏä§Ìä∏"""
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get(f"{CORE_API_URL}/api/v1/query/health")
            response.raise_for_status()
            return {
                "core_api_status": "reachable",
                "core_api_response": response.json()
            }
    except httpx.HTTPError as e:
        return {
            "core_api_status": "unreachable",
            "error": str(e)
        }


@router.get("/chat/config")
async def get_config():
    """ÌòÑÏû¨ ÏÑ§Ï†ï ÌôïÏù∏ (ÎîîÎ≤ÑÍπÖÏö©)"""
    return {
        "core_api_url": CORE_API_URL,
        "openai_api_key_set": bool(os.getenv("OPENAI_API_KEY")),
        "anthropic_api_key_set": bool(os.getenv("ANTHROPIC_API_KEY")),
        "rag_enabled": os.getenv("RAG_ENABLED", "true").lower() == "true",
        "database_url_set": bool(os.getenv("DATABASE_URL")),
        "query_plan_validation": {
            "enabled": ENABLE_QUERY_PLAN_VALIDATION,
            "validator_provider": os.getenv("VALIDATOR_LLM_PROVIDER", "openai"),
            "validator_model": os.getenv("VALIDATOR_LLM_MODEL", "gpt-4o-mini"),
            "quality_threshold": float(os.getenv("VALIDATOR_QUALITY_THRESHOLD", "0.8")),
            "use_llm_validation": os.getenv("VALIDATOR_USE_LLM", "true").lower() == "true"
        },
        "step": "8-query-plan-validation"
    }


@router.get("/chat/rag/status")
async def get_rag_status():
    """RAG ÏÑúÎπÑÏä§ ÏÉÅÌÉú ÌôïÏù∏"""
    try:
        rag_service = get_rag_service()
        doc_counts = await rag_service.get_document_count()

        return {
            "status": "available",
            "rag_enabled": os.getenv("RAG_ENABLED", "true").lower() == "true",
            "openai_configured": bool(os.getenv("OPENAI_API_KEY")),
            "document_counts": doc_counts,
            "total_documents": sum(doc_counts.values()) if doc_counts else 0
        }
    except Exception as e:
        return {
            "status": "unavailable",
            "error": str(e)
        }


@router.post("/chat/rag/search")
async def search_documents(query: str, k: int = 3):
    """RAG Î¨∏ÏÑú Í≤ÄÏÉâ ÌÖåÏä§Ìä∏"""
    try:
        rag_service = get_rag_service()
        documents = await rag_service.search_docs(query=query, k=k)

        return {
            "query": query,
            "count": len(documents),
            "documents": [
                {
                    "id": doc.id,
                    "doc_type": doc.doc_type,
                    "title": doc.title,
                    "content": doc.content[:200] + "..." if len(doc.content) > 200 else doc.content,
                    "similarity": doc.similarity
                }
                for doc in documents
            ]
        }
    except Exception as e:
        return {
            "query": query,
            "error": str(e)
        }


# ============================================
# ÎåÄÏö©Îüâ Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú ÏóîÎìúÌè¨Ïù∏Ìä∏
# ============================================

class DownloadRequest(BaseModel):
    """Îã§Ïö¥Î°úÎìú ÏöîÏ≤≠"""
    sql: str
    format: str = "csv"  # csv ÎòêÎäî excel


@router.post("/chat/download")
async def download_query_result(request: DownloadRequest):
    """
    ÎåÄÏö©Îüâ ÏøºÎ¶¨ Í≤∞Í≥º Îã§Ïö¥Î°úÎìú

    - SQL Ïû¨Í≤ÄÏ¶ù ÌõÑ Ïã§Ìñâ (LIMIT ÏóÜÏù¥)
    - Streaming ÏùëÎãµÏúºÎ°ú Î©îÎ™®Î¶¨ Ìö®Ïú®Ìôî
    """
    if not ENABLE_TEXT_TO_SQL:
        raise HTTPException(400, "Text-to-SQL mode is not enabled")

    from app.services.sql_validator import get_sql_validator
    from app.services.text_to_sql import get_text_to_sql_service

    # SQL Í≤ÄÏ¶ù (Î≥¥Ïïà)
    validator = get_sql_validator()
    validation = validator.validate(request.sql)

    if not validation.is_valid:
        raise HTTPException(400, f"Invalid SQL: {', '.join(validation.issues)}")

    # LIMIT Ï†úÍ±∞ (Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ Îã§Ïö¥Î°úÎìú)
    unlimited_sql = re.sub(r'\bLIMIT\s+\d+', '', validation.sanitized_sql, flags=re.IGNORECASE)
    unlimited_sql = re.sub(r'\bOFFSET\s+\d+', '', unlimited_sql, flags=re.IGNORECASE)

    logger.info(f"Download request - Original SQL: {request.sql[:100]}...")
    logger.info(f"Download request - Unlimited SQL: {unlimited_sql[:100]}...")

    text_to_sql = get_text_to_sql_service()

    def generate_csv() -> Generator[str, None, None]:
        """CSV Ïä§Ìä∏Î¶¨Î∞ç ÏÉùÏÑ±Í∏∞"""
        import psycopg
        from psycopg.rows import dict_row

        try:
            with text_to_sql._get_readonly_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute(unlimited_sql)

                    # Ìó§Îçî Ï∂úÎ†•
                    columns = [desc[0] for desc in cur.description]
                    output = io.StringIO()
                    writer = csv.writer(output)
                    writer.writerow(columns)
                    yield output.getvalue()

                    # Îç∞Ïù¥ÌÑ∞ Î∞∞Ïπò Ï≤òÎ¶¨ (1000Í±¥Ïî©)
                    batch_size = 1000
                    row_count = 0
                    while True:
                        rows = cur.fetchmany(batch_size)
                        if not rows:
                            break

                        output = io.StringIO()
                        writer = csv.writer(output)
                        for row in rows:
                            # datetime Î≥ÄÌôò
                            processed_row = []
                            for value in row.values() if hasattr(row, 'values') else row:
                                if hasattr(value, 'isoformat'):
                                    processed_row.append(value.isoformat())
                                else:
                                    processed_row.append(value)
                            writer.writerow(processed_row)
                            row_count += 1

                        yield output.getvalue()

                    logger.info(f"Download completed: {row_count} rows")

        except psycopg.Error as e:
            logger.error(f"Download SQL execution failed: {e}")
            yield f"Error: {str(e)}"

    # ÌååÏùºÎ™Ö ÏÉùÏÑ±
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    filename = f"query_result_{timestamp}.csv"

    return StreamingResponse(
        generate_csv(),
        media_type="text/csv; charset=utf-8",
        headers={
            "Content-Disposition": f"attachment; filename={filename}",
            "X-Content-Type-Options": "nosniff"
        }
    )


# ============================================
# Text-to-SQL Î™®Îìú Ìï∏Îì§Îü¨
# ============================================

async def handle_text_to_sql(
    request: ChatRequest,
    request_id: str,
    start_time: datetime
) -> ChatResponse:
    """
    Text-to-SQL Î™®Îìú Ï≤òÎ¶¨

    AIÍ∞Ä ÏßÅÏ†ë SQLÏùÑ ÏÉùÏÑ±ÌïòÍ≥† ÏùΩÍ∏∞ Ï†ÑÏö© DBÏóêÏÑú Ïã§ÌñâÌï©ÎãàÎã§.
    """
    logger.info(f"[{request_id}] Text-to-SQL mode: processing")

    try:
        text_to_sql = get_text_to_sql_service()

        # Ï∞∏Ï°∞ ÌëúÌòÑ Í∞êÏßÄ (Ïó∞ÏÜç ÎåÄÌôî WHERE Ï°∞Í±¥ Î≥ëÌï©Ïö©)
        is_refinement, ref_type = detect_reference_expression(request.message)
        if is_refinement:
            logger.info(f"[{request_id}] Reference expression detected (type: {ref_type}), will preserve previous WHERE conditions")

        # ÎåÄÌôî Ïù¥Î†• Î≥ÄÌôò (Text-to-SQL ÌòïÏãù)
        sql_history = build_sql_history(request.conversation_history)

        # SQL ÏÉùÏÑ± Î∞è Ïã§Ìñâ (is_refinement Ï†ÑÎã¨)
        result = await text_to_sql.query(
            question=request.message,
            conversation_history=sql_history,
            retry_on_error=True,
            is_refinement=is_refinement
        )

        # Ïã§Ìñâ ÏãúÍ∞Ñ Í≥ÑÏÇ∞
        total_time_ms = int((datetime.utcnow() - start_time).total_seconds() * 1000)

        if result["success"]:
            # ÏÑ±Í≥µ: Îç∞Ïù¥ÌÑ∞Î•º RenderSpecÏúºÎ°ú Î≥ÄÌôò
            render_spec = compose_sql_render_spec(result, request.message)
            query_result = {
                "requestId": request_id,
                "status": "success",
                "data": {
                    "rows": result["data"],
                    "aggregations": {}
                },
                "metadata": {
                    "executionTimeMs": int(result.get("executionTimeMs") or 0),
                    "rowsReturned": result["rowCount"],
                    "totalRows": result["rowCount"],
                    "dataSource": "text_to_sql"
                }
            }
        else:
            # Ïã§Ìå®: ÏóêÎü¨ RenderSpec
            render_spec = {
                "type": "text",
                "title": "ÏøºÎ¶¨ Ïã§Ìñâ Ïò§Î•ò",
                "text": {
                    "content": f"## ÏøºÎ¶¨ Ïã§Ìñâ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§\n\n"
                              f"**ÏßàÎ¨∏**: {request.message}\n\n"
                              f"**Ïò§Î•ò**: {result.get('error', 'Ïïå Ïàò ÏóÜÎäî Ïò§Î•ò')}\n\n"
                              f"**ÏÉùÏÑ±Îêú SQL**:\n```sql\n{result.get('sql', 'N/A')}\n```",
                    "format": "markdown"
                },
                "metadata": {
                    "requestId": request_id,
                    "generatedAt": datetime.utcnow().isoformat() + "Z",
                    "mode": "text_to_sql"
                }
            }
            query_result = {
                "requestId": request_id,
                "status": "error",
                "data": {"rows": [], "aggregations": {}},
                "metadata": {
                    "executionTimeMs": total_time_ms,
                    "rowsReturned": 0,
                    "dataSource": "text_to_sql"
                },
                "error": {
                    "code": "SQL_EXECUTION_ERROR",
                    "message": result.get("error", "Unknown error")
                }
            }

        logger.info(f"[{request_id}] Text-to-SQL completed: success={result['success']}, rows={result['rowCount']}")

        return ChatResponse(
            request_id=request_id,
            render_spec=render_spec,
            query_result=query_result,
            query_plan={
                "mode": "text_to_sql",
                "sql": result.get("sql"),
                "requestId": request_id
            },
            ai_message=f"'{request.message}'Ïóê ÎåÄÌïú Í≤∞Í≥ºÏûÖÎãàÎã§." if result["success"] else "ÏøºÎ¶¨ Ïã§Ìñâ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.",
            timestamp=datetime.utcnow().isoformat() + "Z"
        )

    except Exception as e:
        logger.error(f"[{request_id}] Text-to-SQL error: {e}", exc_info=True)
        total_time_ms = int((datetime.utcnow() - start_time).total_seconds() * 1000)

        error_render_spec = {
            "type": "text",
            "title": "Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò Î∞úÏÉù",
            "text": {
                "content": f"## Text-to-SQL Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§\n\n"
                          f"**ÏöîÏ≤≠**: {request.message}\n\n"
                          f"**Ïò§Î•ò**: {str(e)}\n\n"
                          f"Ïû†Ïãú ÌõÑ Îã§Ïãú ÏãúÎèÑÌï¥Ï£ºÏÑ∏Ïöî.",
                "format": "markdown"
            },
            "metadata": {
                "requestId": request_id,
                "generatedAt": datetime.utcnow().isoformat() + "Z",
                "mode": "text_to_sql"
            }
        }

        return ChatResponse(
            request_id=request_id,
            render_spec=error_render_spec,
            query_result={
                "requestId": request_id,
                "status": "error",
                "data": {"rows": [], "aggregations": {}},
                "metadata": {"executionTimeMs": total_time_ms, "rowsReturned": 0}
            },
            query_plan={"mode": "text_to_sql", "error": str(e)},
            ai_message=f"Ï≤òÎ¶¨ Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}",
            timestamp=datetime.utcnow().isoformat() + "Z"
        )


def build_sql_history(conversation_history: Optional[List[ChatMessageItem]]) -> List[Dict[str, str]]:
    """ÎåÄÌôî Ïù¥Î†•ÏùÑ Text-to-SQL ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò"""
    if not conversation_history:
        return []

    sql_history = []
    for msg in conversation_history[-10:]:  # ÏµúÍ∑º 10Í∞úÎßå
        entry = {
            "role": msg.role,
            "content": msg.content
        }
        # assistant Î©îÏãúÏßÄÏóê SQL Ï†ïÎ≥¥Í∞Ä ÏûàÏúºÎ©¥ Ìè¨Ìï®
        if msg.role == "assistant" and msg.queryPlan:
            if msg.queryPlan.get("mode") == "text_to_sql" and msg.queryPlan.get("sql"):
                entry["sql"] = msg.queryPlan.get("sql")
        sql_history.append(entry)

    return sql_history


def compose_sql_render_spec(result: Dict[str, Any], question: str) -> Dict[str, Any]:
    """SQL Ïã§Ìñâ Í≤∞Í≥ºÎ•º RenderSpecÏúºÎ°ú Î≥ÄÌôò

    - 1000Í±¥ Ï¥àÍ≥º: Îã§Ïö¥Î°úÎìú RenderSpec (ÌÖåÏù¥Î∏î ÌëúÏãú ÏïàÌï®)
    - 1000Í±¥ Ïù¥Ìïò: ÎØ∏Î¶¨Î≥¥Í∏∞ 10Í±¥ + Ï†ÑÏ≤¥Î≥¥Í∏∞ Î™®Îã¨
    """
    data = result.get("data", [])
    row_count = result.get("rowCount", 0)
    total_count = result.get("totalCount") or row_count
    is_truncated = result.get("isTruncated", False)
    PREVIEW_LIMIT = 10  # ÎØ∏Î¶¨Î≥¥Í∏∞ Ìñâ Ïàò
    MAX_DISPLAY_ROWS = 1000  # ÌôîÎ©¥ ÌëúÏãú ÏµúÎåÄ Í±¥Ïàò

    # 1000Í±¥ Ï¥àÍ≥º: Îã§Ïö¥Î°úÎìú RenderSpec Î∞òÌôò
    if is_truncated:
        return {
            "type": "download",
            "title": "ÎåÄÏö©Îüâ Îç∞Ïù¥ÌÑ∞ Ï°∞Ìöå",
            "download": {
                "totalRows": total_count,
                "maxDisplayRows": MAX_DISPLAY_ROWS,
                "message": f"Ï°∞Ìöå Í≤∞Í≥ºÍ∞Ä {total_count:,}Í±¥ÏúºÎ°ú ÌôîÎ©¥ ÌëúÏãú Ï†úÌïú({MAX_DISPLAY_ROWS:,}Í±¥)ÏùÑ Ï¥àÍ≥ºÌï©ÎãàÎã§.",
                "sql": result.get("sql"),
                "formats": ["csv"]
            },
            "metadata": {
                "sql": result.get("sql"),
                "executionTimeMs": result.get("executionTimeMs"),
                "mode": "text_to_sql"
            }
        }

    if not data:
        return {
            "type": "text",
            "title": "Ï°∞Ìöå Í≤∞Í≥º",
            "text": {
                "content": "Ï°∞Ìöå Í≤∞Í≥ºÍ∞Ä ÏóÜÏäµÎãàÎã§.",
                "format": "plain"
            },
            "metadata": {
                "sql": result.get("sql"),
                "executionTimeMs": result.get("executionTimeMs")
            }
        }

    # Îã®Ïùº Ìñâ + ÏßëÍ≥Ñ Í≤∞Í≥ºÏ≤òÎüº Î≥¥Ïù¥Î©¥ ÌÖçÏä§Ìä∏Î°ú ÌëúÏãú
    if row_count == 1 and len(data[0]) <= 3:
        row = data[0]
        # ÌÇ§-Í∞í ÏåçÏúºÎ°ú ÌëúÏãú
        content_parts = []
        for key, value in row.items():
            # Í∏àÏï° Ìè¨Îß∑ÌåÖ
            if isinstance(value, (int, float)) and any(kw in key.lower() for kw in ["amount", "sum", "total", "count", "avg"]):
                if value >= 1000000:
                    formatted = f"‚Ç©{value:,.0f} ({value/1000000:.2f}M)"
                elif value >= 1000:
                    formatted = f"‚Ç©{value:,.0f}"
                else:
                    formatted = f"{value:,.2f}" if isinstance(value, float) else f"{value:,}"
                content_parts.append(f"**{key}**: {formatted}")
            else:
                content_parts.append(f"**{key}**: {value}")

        return {
            "type": "text",
            "title": "ÏßëÍ≥Ñ Í≤∞Í≥º",
            "text": {
                "content": "\n".join(content_parts),
                "format": "markdown"
            },
            "metadata": {
                "sql": result.get("sql"),
                "executionTimeMs": result.get("executionTimeMs"),
                "mode": "text_to_sql"
            }
        }

    # Îã§Ï§ë Ìñâ: ÌÖåÏù¥Î∏îÎ°ú ÌëúÏãú (ÎØ∏Î¶¨Î≥¥Í∏∞ Î™®Îìú)
    if data:
        columns = list(data[0].keys())
        column_defs = []
        for col in columns:
            col_def = {
                "key": col,  # UI TableRenderer Ìò∏Ìôò
                "label": col.replace("_", " ").title(),  # TableRenderer expects 'label'
                "field": col,
                "headerName": col.replace("_", " ").title()
            }
            # Í∏àÏï° ÌïÑÎìú Í∞êÏßÄ
            if any(kw in col.lower() for kw in ["amount", "fee", "net", "total", "price"]):
                col_def["type"] = "currency"
                col_def["currencyCode"] = "KRW"
            # ÎÇ†Ïßú ÌïÑÎìú Í∞êÏßÄ
            elif any(kw in col.lower() for kw in ["date", "time", "at", "created", "updated"]):
                col_def["type"] = "datetime"
            column_defs.append(col_def)

        # ÎØ∏Î¶¨Î≥¥Í∏∞Ïö© Îç∞Ïù¥ÌÑ∞ (ÏµúÎåÄ PREVIEW_LIMITÍ±¥)
        preview_data = data[:PREVIEW_LIMIT]
        has_more = row_count > PREVIEW_LIMIT

        # ÌÉÄÏù¥ÌãÄ: ÎØ∏Î¶¨Î≥¥Í∏∞Ïù∏ Í≤ΩÏö∞ ÌëúÏãú
        if has_more:
            title = f"Ï°∞Ìöå Í≤∞Í≥º ({row_count}Í±¥ Ï§ë {PREVIEW_LIMIT}Í±¥ ÎØ∏Î¶¨Î≥¥Í∏∞)"
        else:
            title = f"Ï°∞Ìöå Í≤∞Í≥º ({row_count}Í±¥)"

        return {
            "type": "table",
            "title": title,
            "table": {
                "columns": column_defs,
                "data": preview_data,  # ÎØ∏Î¶¨Î≥¥Í∏∞Îßå Ï†ÑÏÜ°
                "dataRef": "data.rows",
                "actions": [
                    {"action": "fullscreen", "label": "Ï†ÑÏ≤¥Î≥¥Í∏∞"},
                    {"action": "export-csv", "label": "CSV Îã§Ïö¥Î°úÎìú"}
                ],
                "pagination": {
                    "enabled": False,  # ÎØ∏Î¶¨Î≥¥Í∏∞ÏóêÏÑúÎäî ÌéòÏù¥ÏßÄÎÑ§Ïù¥ÏÖò ÎπÑÌôúÏÑ±Ìôî
                    "pageSize": PREVIEW_LIMIT,
                    "totalRows": row_count
                }
            },
            # Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Îäî Î≥ÑÎèÑÎ°ú Ï†ÄÏû• (Î™®Îã¨ÏóêÏÑú ÏÇ¨Ïö©)
            "fullData": data if has_more else None,
            "preview": {
                "enabled": has_more,
                "previewRows": PREVIEW_LIMIT,
                "totalRows": row_count,
                "message": f"Ï†ÑÏ≤¥ {row_count}Í±¥ Ï§ë {PREVIEW_LIMIT}Í±¥Îßå ÌëúÏãúÎê©ÎãàÎã§. Ï†ÑÏ≤¥Î≥¥Í∏∞ Î≤ÑÌäºÏùÑ ÌÅ¥Î¶≠ÌïòÏÑ∏Ïöî."
            },
            "metadata": {
                "sql": result.get("sql"),
                "executionTimeMs": result.get("executionTimeMs"),
                "mode": "text_to_sql"
            }
        }

    return {
        "type": "text",
        "title": "Í≤∞Í≥º",
        "text": {
            "content": f"Ï°∞Ìöå ÏôÑÎ£å: {row_count}Í±¥",
            "format": "plain"
        }
    }
